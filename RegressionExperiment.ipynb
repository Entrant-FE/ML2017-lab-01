{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss of the ', 0, ' iteration for train:', 303.84734828496045)\n",
      "('Loss of the ', 0, ' iteration for validation:', 272.87421259842517)\n",
      "('Loss of the ', 1, ' iteration for train:', 278.79840166235613)\n",
      "('Loss of the ', 1, ' iteration for validation:', 249.58771907492346)\n",
      "('Loss of the ', 2, ' iteration for train:', 256.12693604313921)\n",
      "('Loss of the ', 2, ' iteration for validation:', 228.52396878183538)\n",
      "('Loss of the ', 3, ' iteration for train:', 235.60599620153803)\n",
      "('Loss of the ', 3, ' iteration for validation:', 209.47007845411355)\n",
      "('Loss of the ', 4, ' iteration for train:', 217.03030969594678)\n",
      "('Loss of the ', 4, ' iteration for validation:', 192.23353647481287)\n",
      "('Loss of the ', 5, ' iteration for train:', 200.21421487629075)\n",
      "('Loss of the ', 5, ' iteration for validation:', 176.64025475428841)\n",
      "('Loss of the ', 6, ' iteration for train:', 184.98978690428135)\n",
      "('Loss of the ', 6, ' iteration for validation:', 162.53280683782441)\n",
      "('Loss of the ', 7, ' iteration for train:', 171.20514286271356)\n",
      "('Loss of the ', 7, ' iteration for validation:', 149.76883444251658)\n",
      "('Loss of the ', 8, ' iteration for train:', 158.72290883850349)\n",
      "('Loss of the ', 8, ' iteration for validation:', 138.21960632529596)\n",
      "('Loss of the ', 9, ' iteration for train:', 147.41883349986358)\n",
      "('Loss of the ', 9, ' iteration for validation:', 127.76871492248546)\n",
      "('Loss of the ', 10, ' iteration for train:', 137.18053416739141)\n",
      "('Loss of the ', 10, ' iteration for validation:', 118.31089759274647)\n",
      "('Loss of the ', 11, ' iteration for train:', 127.90636271684284)\n",
      "('Loss of the ', 11, ' iteration for validation:', 109.75097055376779)\n",
      "('Loss of the ', 12, ' iteration for train:', 119.50437986147936)\n",
      "('Loss of the ', 12, ' iteration for validation:', 102.00286474126476)\n",
      "('Loss of the ', 13, ' iteration for train:', 111.89142745635448)\n",
      "('Loss of the ', 13, ' iteration for validation:', 94.988753848301357)\n",
      "('Loss of the ', 14, ' iteration for train:', 104.99228945677309)\n",
      "('Loss of the ', 14, ' iteration for validation:', 88.638265734007618)\n",
      "('Loss of the ', 15, ' iteration for train:', 98.738933058431186)\n",
      "('Loss of the ', 15, ' iteration for validation:', 82.887769232847148)\n",
      "('Loss of the ', 16, ' iteration for train:', 93.069822356451041)\n",
      "('Loss of the ', 16, ' iteration for validation:', 77.67972915719325)\n",
      "('Loss of the ', 17, ' iteration for train:', 87.929297592855463)\n",
      "('Loss of the ', 17, ' iteration for validation:', 72.962122974793715)\n",
      "('Loss of the ', 18, ' iteration for train:', 83.267013724360268)\n",
      "('Loss of the ', 18, ' iteration for validation:', 68.687913265694718)\n",
      "('Loss of the ', 19, ' iteration for train:', 79.037432641405459)\n",
      "('Loss of the ', 19, ' iteration for validation:', 64.814570626645278)\n",
      "('Loss of the ', 20, ' iteration for train:', 75.199363911131911)\n",
      "('Loss of the ', 20, ' iteration for validation:', 61.303642200609794)\n",
      "('Loss of the ', 21, ' iteration for train:', 71.715549407021527)\n",
      "('Loss of the ', 21, ' iteration for validation:', 58.120361469916887)\n",
      "('Loss of the ', 22, ' iteration for train:', 68.55228763109946)\n",
      "('Loss of the ', 22, ' iteration for validation:', 55.233295368426219)\n",
      "('Loss of the ', 23, ' iteration for train:', 65.67909393542088)\n",
      "('Loss of the ', 23, ' iteration for validation:', 52.614025145111533)\n",
      "('Loss of the ', 24, ' iteration for train:', 63.068393212085319)\n",
      "('Loss of the ', 24, ' iteration for validation:', 50.236857752441239)\n",
      "('Loss of the ', 25, ' iteration for train:', 60.695241948893333)\n",
      "('Loss of the ', 25, ' iteration for validation:', 48.078564841335059)\n",
      "('Loss of the ', 26, ' iteration for train:', 58.537076844299207)\n",
      "('Loss of the ', 26, ' iteration for validation:', 46.118146723397935)\n",
      "('Loss of the ', 27, ' iteration for train:', 56.573487443511745)\n",
      "('Loss of the ', 27, ' iteration for validation:', 44.336618913398503)\n",
      "('Loss of the ', 28, ' iteration for train:', 54.786010500161495)\n",
      "('Loss of the ', 28, ' iteration for validation:', 42.716819093116506)\n",
      "('Loss of the ', 29, ' iteration for train:', 53.157943987338356)\n",
      "('Loss of the ', 29, ' iteration for validation:', 41.243232544034761)\n",
      "('Loss of the ', 30, ' iteration for train:', 51.67417888022085)\n",
      "('Loss of the ', 30, ' iteration for validation:', 39.901834282982591)\n",
      "('Loss of the ', 31, ' iteration for train:', 50.321047011974763)\n",
      "('Loss of the ', 31, ' iteration for validation:', 38.679946303630089)\n",
      "('Loss of the ', 32, ' iteration for train:', 49.086183466903655)\n",
      "('Loss of the ', 32, ' iteration for validation:', 37.566108479394806)\n",
      "('Loss of the ', 33, ' iteration for train:', 47.958402121627678)\n",
      "('Loss of the ', 33, ' iteration for validation:', 36.549961821394398)\n",
      "('Loss of the ', 34, ' iteration for train:', 46.927583077831592)\n",
      "('Loss of the ', 34, ' iteration for validation:', 35.622142909952601)\n",
      "('Loss of the ', 35, ' iteration for train:', 45.984570850200001)\n",
      "('Loss of the ', 35, ' iteration for validation:', 34.774188431107831)\n",
      "('Loss of the ', 36, ' iteration for train:', 45.121082281758305)\n",
      "('Loss of the ', 36, ' iteration for validation:', 33.998448851719111)\n",
      "('Loss of the ', 37, ' iteration for train:', 44.329623257060312)\n",
      "('Loss of the ', 37, ' iteration for validation:', 33.288010359147748)\n",
      "('Loss of the ', 38, ' iteration for train:', 43.603413372498245)\n",
      "('Loss of the ', 38, ' iteration for validation:', 32.636624275047225)\n",
      "('Loss of the ', 39, ' iteration for train:', 42.936317803356594)\n",
      "('Loss of the ', 39, ' iteration for validation:', 32.038643228361217)\n",
      "('Loss of the ', 40, ' iteration for train:', 42.322785679896953)\n",
      "('Loss of the ', 40, ' iteration for validation:', 31.488963440975983)\n",
      "('Loss of the ', 41, ' iteration for train:', 41.757794350484588)\n",
      "('Loss of the ', 41, ' iteration for validation:', 30.982972541285278)\n",
      "('Loss of the ', 42, ' iteration for train:', 41.236798969207058)\n",
      "('Loss of the ', 42, ' iteration for validation:', 30.516502376831781)\n",
      "('Loss of the ', 43, ' iteration for train:', 40.755686899196355)\n",
      "('Loss of the ', 43, ' iteration for validation:', 30.085786347749966)\n",
      "('Loss of the ', 44, ' iteration for train:', 40.310736471488774)\n",
      "('Loss of the ', 44, ' iteration for validation:', 29.687420828464219)\n",
      "('Loss of the ', 45, ' iteration for train:', 39.898579683231759)\n",
      "('Loss of the ', 45, ' iteration for validation:', 29.318330286453929)\n",
      "('Loss of the ', 46, ' iteration for train:', 39.516168458820935)\n",
      "('Loss of the ', 46, ' iteration for validation:', 28.975735744301694)\n",
      "('Loss of the ', 47, ' iteration for train:', 39.16074413352203)\n",
      "('Loss of the ', 47, ' iteration for validation:', 28.657126265070278)\n",
      "('Loss of the ', 48, ' iteration for train:', 38.829809851666617)\n",
      "('Loss of the ', 48, ' iteration for validation:', 28.360233171649451)\n",
      "('Loss of the ', 49, ' iteration for train:', 38.521105600936593)\n",
      "('Loss of the ', 49, ' iteration for validation:', 28.083006738385009)\n",
      "('Loss of the ', 50, ' iteration for train:', 38.23258563086349)\n",
      "('Loss of the ', 50, ' iteration for validation:', 27.823595118328022)\n",
      "('Loss of the ', 51, ' iteration for train:', 37.962398027740399)\n",
      "('Loss of the ', 51, ' iteration for validation:', 27.580325292076175)\n",
      "('Loss of the ', 52, ' iteration for train:', 37.708866239911941)\n",
      "('Loss of the ', 52, ' iteration for validation:', 27.351685844648959)\n",
      "('Loss of the ', 53, ' iteration for train:', 37.470472367097713)\n",
      "('Loss of the ', 53, ' iteration for validation:', 27.136311395351846)\n",
      "('Loss of the ', 54, ' iteration for train:', 37.245842045211418)\n",
      "('Loss of the ', 54, ' iteration for validation:', 26.932968522327371)\n",
      "('Loss of the ', 55, ' iteration for train:', 37.03373077424331)\n",
      "('Loss of the ', 55, ' iteration for validation:', 26.740543038634382)\n",
      "('Loss of the ', 56, ' iteration for train:', 36.833011551340626)\n",
      "('Loss of the ', 56, ' iteration for validation:', 26.558028490391191)\n",
      "('Loss of the ', 57, ' iteration for train:', 36.642663684394002)\n",
      "('Loss of the ', 57, ' iteration for validation:', 26.384515759904041)\n",
      "('Loss of the ', 58, ' iteration for train:', 36.461762673353988)\n",
      "('Loss of the ', 58, ' iteration for validation:', 26.219183667904115)\n",
      "('Loss of the ', 59, ' iteration for train:', 36.289471057277964)\n",
      "('Loss of the ', 59, ' iteration for validation:', 26.061290479146397)\n",
      "('Loss of the ', 60, ' iteration for train:', 36.125030134854299)\n",
      "('Loss of the ', 60, ' iteration for validation:', 25.910166224785751)\n",
      "('Loss of the ', 61, ' iteration for train:', 35.967752474966559)\n",
      "('Loss of the ', 61, ' iteration for validation:', 25.765205763231471)\n",
      "('Loss of the ', 62, ' iteration for train:', 35.817015141832705)\n",
      "('Loss of the ', 62, ' iteration for validation:', 25.625862508674949)\n",
      "('Loss of the ', 63, ' iteration for train:', 35.672253566465074)\n",
      "('Loss of the ', 63, ' iteration for validation:', 25.491642763262053)\n",
      "('Loss of the ', 64, ' iteration for train:', 35.532956002719743)\n",
      "('Loss of the ', 64, ' iteration for validation:', 25.362100595010897)\n",
      "('Loss of the ', 65, ' iteration for train:', 35.398658512101214)\n",
      "('Loss of the ', 65, ' iteration for validation:', 25.236833209118291)\n",
      "('Loss of the ', 66, ' iteration for train:', 35.268940426823804)\n",
      "('Loss of the ', 66, ' iteration for validation:', 25.115476765310717)\n",
      "('Loss of the ', 67, ' iteration for train:', 35.143420245456412)\n",
      "('Loss of the ', 67, ' iteration for validation:', 24.997702598429267)\n",
      "('Loss of the ', 68, ' iteration for train:', 35.021751919840739)\n",
      "('Loss of the ', 68, ' iteration for validation:', 24.883213803537213)\n",
      "('Loss of the ', 69, ' iteration for train:', 34.903621495920262)\n",
      "('Loss of the ', 69, ' iteration for validation:', 24.771742150546881)\n",
      "('Loss of the ', 70, ' iteration for train:', 34.788744074687187)\n",
      "('Loss of the ', 70, ' iteration for validation:', 24.663045296714802)\n",
      "('Loss of the ', 71, ' iteration for train:', 34.676861062682846)\n",
      "('Loss of the ', 71, ' iteration for validation:', 24.556904268386671)\n",
      "('Loss of the ', 72, ' iteration for train:', 34.567737684407298)\n",
      "('Loss of the ', 72, ' iteration for validation:', 24.453121186115709)\n",
      "('Loss of the ', 73, ' iteration for train:', 34.46116073163504)\n",
      "('Loss of the ', 73, ' iteration for validation:', 24.351517209757031)\n",
      "('Loss of the ', 74, ' iteration for train:', 34.356936527022199)\n",
      "('Loss of the ', 74, ' iteration for validation:', 24.25193068238417)\n",
      "('Loss of the ', 75, ' iteration for train:', 34.254889081551291)\n",
      "('Loss of the ', 75, ' iteration for validation:', 24.154215453900612)\n",
      "('Loss of the ', 76, ' iteration for train:', 34.154858427313066)\n",
      "('Loss of the ', 76, ' iteration for validation:', 24.05823936705378)\n",
      "('Loss of the ', 77, ' iteration for train:', 34.056699108893)\n",
      "('Loss of the ', 77, ' iteration for validation:', 23.963882890216851)\n",
      "('Loss of the ', 78, ' iteration for train:', 33.960278818227643)\n",
      "('Loss of the ', 78, ' iteration for validation:', 23.871037882803215)\n",
      "('Loss of the ', 79, ' iteration for train:', 33.865477159242083)\n",
      "('Loss of the ', 79, ' iteration for validation:', 23.779606480534813)\n",
      "('Loss of the ', 80, ' iteration for train:', 33.772184529887319)\n",
      "('Loss of the ', 80, ' iteration for validation:', 23.689500089011418)\n",
      "('Loss of the ', 81, ' iteration for train:', 33.680301110378721)\n",
      "('Loss of the ', 81, ' iteration for validation:', 23.600638475136723)\n",
      "('Loss of the ', 82, ' iteration for train:', 33.589735947506448)\n",
      "('Loss of the ', 82, ' iteration for validation:', 23.512948946960023)\n",
      "('Loss of the ', 83, ' iteration for train:', 33.500406125856045)\n",
      "('Loss of the ', 83, ' iteration for validation:', 23.426365613398595)\n",
      "('Loss of the ', 84, ' iteration for train:', 33.412236017652525)\n",
      "('Loss of the ', 84, ' iteration for validation:', 23.340828716125685)\n",
      "('Loss of the ', 85, ' iteration for train:', 33.325156603732424)\n",
      "('Loss of the ', 85, ' iteration for validation:', 23.256284026650295)\n",
      "('Loss of the ', 86, ' iteration for train:', 33.239104858864117)\n",
      "('Loss of the ', 86, ' iteration for validation:', 23.172682302285306)\n",
      "('Loss of the ', 87, ' iteration for train:', 33.154023195283976)\n",
      "('Loss of the ', 87, ' iteration for validation:', 23.089978795306276)\n",
      "('Loss of the ', 88, ' iteration for train:', 33.069858958901861)\n",
      "('Loss of the ', 88, ' iteration for validation:', 23.008132810151167)\n",
      "('Loss of the ', 89, ' iteration for train:', 32.98656397315829)\n",
      "('Loss of the ', 89, ' iteration for validation:', 22.927107304006924)\n",
      "('Loss of the ', 90, ' iteration for train:', 32.904094125995137)\n",
      "('Loss of the ', 90, ' iteration for validation:', 22.846868526576497)\n",
      "('Loss of the ', 91, ' iteration for train:', 32.822408995835104)\n",
      "('Loss of the ', 91, ' iteration for validation:', 22.767385695224817)\n",
      "('Loss of the ', 92, ' iteration for train:', 32.74147151285613)\n",
      "('Loss of the ', 92, ' iteration for validation:', 22.688630702068821)\n",
      "('Loss of the ', 93, ' iteration for train:', 32.661247652202547)\n",
      "('Loss of the ', 93, ' iteration for validation:', 22.610577849906765)\n",
      "('Loss of the ', 94, ' iteration for train:', 32.581706156094221)\n",
      "('Loss of the ', 94, ' iteration for validation:', 22.53320361418232)\n",
      "('Loss of the ', 95, ' iteration for train:', 32.502818282085528)\n",
      "('Loss of the ', 95, ' iteration for validation:', 22.456486428448809)\n",
      "('Loss of the ', 96, ' iteration for train:', 32.424557574988143)\n",
      "('Loss of the ', 96, ' iteration for validation:', 22.380406491043502)\n",
      "('Loss of the ', 97, ' iteration for train:', 32.346899660208301)\n",
      "('Loss of the ', 97, ' iteration for validation:', 22.304945590903376)\n",
      "('Loss of the ', 98, ' iteration for train:', 32.269822056464641)\n",
      "('Loss of the ', 98, ' iteration for validation:', 22.230086950653426)\n",
      "('Loss of the ', 99, ' iteration for train:', 32.193304006045764)\n",
      "('Loss of the ', 99, ' iteration for validation:', 22.155815085278785)\n",
      "('Loss of the ', 100, ' iteration for train:', 32.117326320943086)\n",
      "('Loss of the ', 100, ' iteration for validation:', 22.082115674856063)\n",
      "('Loss of the ', 101, ' iteration for train:', 32.041871243352375)\n",
      "('Loss of the ', 101, ' iteration for validation:', 22.008975449966169)\n",
      "('Loss of the ', 102, ' iteration for train:', 31.966922319181919)\n",
      "('Loss of the ', 102, ' iteration for validation:', 21.936382088544658)\n",
      "('Loss of the ', 103, ' iteration for train:', 31.892464283334331)\n",
      "('Loss of the ', 103, ' iteration for validation:', 21.86432412304611)\n",
      "('Loss of the ', 104, ' iteration for train:', 31.81848295564696)\n",
      "('Loss of the ', 104, ' iteration for validation:', 21.792790856907867)\n",
      "('Loss of the ', 105, ' iteration for train:', 31.744965146481881)\n",
      "('Loss of the ', 105, ' iteration for validation:', 21.72177228939734)\n",
      "('Loss of the ', 106, ' iteration for train:', 31.671898571052775)\n",
      "('Loss of the ', 106, ' iteration for validation:', 21.651259048015536)\n",
      "('Loss of the ', 107, ' iteration for train:', 31.599271771662732)\n",
      "('Loss of the ', 107, ' iteration for validation:', 21.581242327710317)\n",
      "('Loss of the ', 108, ' iteration for train:', 31.5270740471057)\n",
      "('Loss of the ', 108, ' iteration for validation:', 21.511713836225283)\n",
      "('Loss of the ', 109, ' iteration for train:', 31.455295388555545)\n",
      "('Loss of the ', 109, ' iteration for validation:', 21.442665744976122)\n",
      "('Loss of the ', 110, ' iteration for train:', 31.383926421331068)\n",
      "('Loss of the ', 110, ' iteration for validation:', 21.374090644905131)\n",
      "('Loss of the ', 111, ' iteration for train:', 31.31295835198306)\n",
      "('Loss of the ', 111, ' iteration for validation:', 21.305981506818824)\n",
      "('Loss of the ', 112, ' iteration for train:', 31.242382920202878)\n",
      "('Loss of the ', 112, ' iteration for validation:', 21.238331645761232)\n",
      "('Loss of the ', 113, ' iteration for train:', 31.172192355099099)\n",
      "('Loss of the ', 113, ' iteration for validation:', 21.171134689020004)\n",
      "('Loss of the ', 114, ' iteration for train:', 31.102379335431859)\n",
      "('Loss of the ', 114, ' iteration for validation:', 21.10438454740126)\n",
      "('Loss of the ', 115, ' iteration for train:', 31.032936953434042)\n",
      "('Loss of the ', 115, ' iteration for validation:', 21.03807538944525)\n",
      "('Loss of the ', 116, ' iteration for train:', 30.96385868188289)\n",
      "('Loss of the ', 116, ' iteration for validation:', 20.972201618286938)\n",
      "('Loss of the ', 117, ' iteration for train:', 30.895138344118408)\n",
      "('Loss of the ', 117, ' iteration for validation:', 20.906757850894749)\n",
      "('Loss of the ', 118, ' iteration for train:', 30.826770086732829)\n",
      "('Loss of the ', 118, ' iteration for validation:', 20.841738899446998)\n",
      "('Loss of the ', 119, ' iteration for train:', 30.758748354682478)\n",
      "('Loss of the ', 119, ' iteration for validation:', 20.77713975462926)\n",
      "('Loss of the ', 120, ' iteration for train:', 30.691067868596207)\n",
      "('Loss of the ', 120, ' iteration for validation:', 20.712955570657424)\n",
      "('Loss of the ', 121, ' iteration for train:', 30.623723604076293)\n",
      "('Loss of the ', 121, ' iteration for validation:', 20.649181651850341)\n",
      "('Loss of the ', 122, ' iteration for train:', 30.556710772807111)\n",
      "('Loss of the ', 122, ' iteration for validation:', 20.585813440593629)\n",
      "('Loss of the ', 123, ' iteration for train:', 30.490024805304014)\n",
      "('Loss of the ', 123, ' iteration for validation:', 20.522846506551897)\n",
      "('Loss of the ', 124, ' iteration for train:', 30.423661335151131)\n",
      "('Loss of the ', 124, ' iteration for validation:', 20.460276537000681)\n",
      "('Loss of the ', 125, ' iteration for train:', 30.357616184590615)\n",
      "('Loss of the ', 125, ' iteration for validation:', 20.398099328162662)\n",
      "('Loss of the ', 126, ' iteration for train:', 30.291885351339346)\n",
      "('Loss of the ', 126, ' iteration for validation:', 20.336310777443678)\n",
      "('Loss of the ', 127, ' iteration for train:', 30.226464996520338)\n",
      "('Loss of the ', 127, ' iteration for validation:', 20.274906876475185)\n",
      "('Loss of the ', 128, ' iteration for train:', 30.161351433606985)\n",
      "('Loss of the ', 128, ' iteration for validation:', 20.213883704878647)\n",
      "('Loss of the ', 129, ' iteration for train:', 30.09654111828786)\n",
      "('Loss of the ', 129, ' iteration for validation:', 20.153237424676181)\n",
      "('Loss of the ', 130, ' iteration for train:', 30.032030639168319)\n",
      "('Loss of the ', 130, ' iteration for validation:', 20.092964275279375)\n",
      "('Loss of the ', 131, ' iteration for train:', 29.967816709233105)\n",
      "('Loss of the ', 131, ' iteration for validation:', 20.033060568994909)\n",
      "('Loss of the ', 132, ' iteration for train:', 29.903896158001398)\n",
      "('Loss of the ', 132, ' iteration for validation:', 19.973522686992268)\n",
      "('Loss of the ', 133, ' iteration for train:', 29.840265924311893)\n",
      "('Loss of the ', 133, ' iteration for validation:', 19.914347075683896)\n",
      "('Loss of the ', 134, ' iteration for train:', 29.776923049681496)\n",
      "('Loss of the ', 134, ' iteration for validation:', 19.855530243473574)\n",
      "('Loss of the ', 135, ' iteration for train:', 29.71386467218661)\n",
      "('Loss of the ', 135, ' iteration for validation:', 19.797068757833394)\n",
      "('Loss of the ', 136, ' iteration for train:', 29.651088020820492)\n",
      "('Loss of the ', 136, ' iteration for validation:', 19.738959242673388)\n",
      "('Loss of the ', 137, ' iteration for train:', 29.588590410284681)\n",
      "('Loss of the ', 137, ' iteration for validation:', 19.681198375972173)\n",
      "('Loss of the ', 138, ' iteration for train:', 29.526369236176219)\n",
      "('Loss of the ', 138, ' iteration for validation:', 19.623782887639614)\n",
      "('Loss of the ', 139, ' iteration for train:', 29.464421970536371)\n",
      "('Loss of the ', 139, ' iteration for validation:', 19.566709557586169)\n",
      "('Loss of the ', 140, ' iteration for train:', 29.40274615772897)\n",
      "('Loss of the ', 140, ' iteration for validation:', 19.509975213975771)\n",
      "('Loss of the ', 141, ' iteration for train:', 29.341339410620233)\n",
      "('Loss of the ', 141, ' iteration for validation:', 19.453576731641732)\n",
      "('Loss of the ', 142, ' iteration for train:', 29.280199407034079)\n",
      "('Loss of the ', 142, ' iteration for validation:', 19.397511030647383)\n",
      "('Loss of the ', 143, ' iteration for train:', 29.219323886459417)\n",
      "('Loss of the ', 143, ' iteration for validation:', 19.341775074975025)\n",
      "('Loss of the ', 144, ' iteration for train:', 29.158710646988016)\n",
      "('Loss of the ', 144, ' iteration for validation:', 19.286365871328403)\n",
      "('Loss of the ', 145, ' iteration for train:', 29.098357542463635)\n",
      "('Loss of the ', 145, ' iteration for validation:', 19.231280468035937)\n",
      "('Loss of the ', 146, ' iteration for train:', 29.038262479824848)\n",
      "('Loss of the ', 146, ' iteration for validation:', 19.176515954042742)\n",
      "('Loss of the ', 147, ' iteration for train:', 28.97842341662539)\n",
      "('Loss of the ', 147, ' iteration for validation:', 19.122069457981326)\n",
      "('Loss of the ', 148, ' iteration for train:', 28.918838358717586)\n",
      "('Loss of the ', 148, ' iteration for validation:', 19.067938147311565)\n",
      "('Loss of the ', 149, ' iteration for train:', 28.859505358085471)\n",
      "('Loss of the ', 149, ' iteration for validation:', 19.01411922752186)\n",
      "('Loss of the ', 150, ' iteration for train:', 28.80042251081581)\n",
      "('Loss of the ', 150, ' iteration for validation:', 18.960609941384138)\n",
      "('Loss of the ', 151, ' iteration for train:', 28.741587955195616)\n",
      "('Loss of the ', 151, ' iteration for validation:', 18.907407568256254)\n",
      "('Loss of the ', 152, ' iteration for train:', 28.68299986992665)\n",
      "('Loss of the ', 152, ' iteration for validation:', 18.854509423426077)\n",
      "('Loss of the ', 153, ' iteration for train:', 28.624656472447271)\n",
      "('Loss of the ', 153, ' iteration for validation:', 18.801912857492209)\n",
      "('Loss of the ', 154, ' iteration for train:', 28.566556017354007)\n",
      "('Loss of the ', 154, ' iteration for validation:', 18.749615255776739)\n",
      "('Loss of the ', 155, ' iteration for train:', 28.508696794914385)\n",
      "('Loss of the ', 155, ' iteration for validation:', 18.697614037766321)\n",
      "('Loss of the ', 156, ' iteration for train:', 28.451077129664952)\n",
      "('Loss of the ', 156, ' iteration for validation:', 18.645906656577917)\n",
      "('Loss of the ', 157, ' iteration for train:', 28.393695379087713)\n",
      "('Loss of the ', 157, ' iteration for validation:', 18.594490598446072)\n",
      "('Loss of the ', 158, ' iteration for train:', 28.336549932359272)\n",
      "('Loss of the ', 158, ' iteration for validation:', 18.543363382229401)\n",
      "('Loss of the ', 159, ' iteration for train:', 28.279639209167531)\n",
      "('Loss of the ', 159, ' iteration for validation:', 18.492522558933462)\n",
      "('Loss of the ', 160, ' iteration for train:', 28.222961658590943)\n",
      "('Loss of the ', 160, ' iteration for validation:', 18.441965711248272)\n",
      "('Loss of the ', 161, ' iteration for train:', 28.166515758036216)\n",
      "('Loss of the ', 161, ' iteration for validation:', 18.391690453098715)\n",
      "('Loss of the ', 162, ' iteration for train:', 28.110300012230002)\n",
      "('Loss of the ', 162, ' iteration for validation:', 18.341694429205916)\n",
      "('Loss of the ', 163, ' iteration for train:', 28.054312952261295)\n",
      "('Loss of the ', 163, ' iteration for validation:', 18.291975314658746)\n",
      "('Loss of the ', 164, ' iteration for train:', 27.998553134670779)\n",
      "('Loss of the ', 164, ' iteration for validation:', 18.242530814493907)\n",
      "('Loss of the ', 165, ' iteration for train:', 27.94301914058433)\n",
      "('Loss of the ', 165, ' iteration for validation:', 18.193358663283639)\n",
      "('Loss of the ', 166, ' iteration for train:', 27.887709574887463)\n",
      "('Loss of the ', 166, ' iteration for validation:', 18.144456624730473)\n",
      "('Loss of the ', 167, ' iteration for train:', 27.83262306543855)\n",
      "('Loss of the ', 167, ' iteration for validation:', 18.095822491267938)\n",
      "('Loss of the ', 168, ' iteration for train:', 27.777758262317839)\n",
      "('Loss of the ', 168, ' iteration for validation:', 18.047454083666782)\n",
      "('Loss of the ', 169, ' iteration for train:', 27.723113837110454)\n",
      "('Loss of the ', 169, ' iteration for validation:', 17.999349250646279)\n",
      "('Loss of the ', 170, ' iteration for train:', 27.668688482221253)\n",
      "('Loss of the ', 170, ' iteration for validation:', 17.951505868489896)\n",
      "('Loss of the ', 171, ' iteration for train:', 27.614480910219513)\n",
      "('Loss of the ', 171, ' iteration for validation:', 17.903921840665301)\n",
      "('Loss of the ', 172, ' iteration for train:', 27.560489853211639)\n",
      "('Loss of the ', 172, ' iteration for validation:', 17.856595097448103)\n",
      "('Loss of the ', 173, ' iteration for train:', 27.506714062240651)\n",
      "('Loss of the ', 173, ' iteration for validation:', 17.80952359554934)\n",
      "('Loss of the ', 174, ' iteration for train:', 27.453152306710507)\n",
      "('Loss of the ', 174, ' iteration for validation:', 17.762705317746381)\n",
      "('Loss of the ', 175, ' iteration for train:', 27.399803373834107)\n",
      "('Loss of the ', 175, ' iteration for validation:', 17.716138272517085)\n",
      "('Loss of the ', 176, ' iteration for train:', 27.346666068103655)\n",
      "('Loss of the ', 176, ' iteration for validation:', 17.669820493677204)\n",
      "('Loss of the ', 177, ' iteration for train:', 27.293739210782189)\n",
      "('Loss of the ', 177, ' iteration for validation:', 17.623750040020873)\n",
      "('Loss of the ', 178, ' iteration for train:', 27.241021639415106)\n",
      "('Loss of the ', 178, ' iteration for validation:', 17.577924994964139)\n",
      "('Loss of the ', 179, ' iteration for train:', 27.188512207360752)\n",
      "('Loss of the ', 179, ' iteration for validation:', 17.532343466191545)\n",
      "('Loss of the ', 180, ' iteration for train:', 27.136209783339005)\n",
      "('Loss of the ', 180, ' iteration for validation:', 17.487003585305679)\n",
      "('Loss of the ', 181, ' iteration for train:', 27.084113250996996)\n",
      "('Loss of the ', 181, ' iteration for validation:', 17.441903507479768)\n",
      "('Loss of the ', 182, ' iteration for train:', 27.032221508491197)\n",
      "('Loss of the ', 182, ' iteration for validation:', 17.397041411113303)\n",
      "('Loss of the ', 183, ' iteration for train:', 26.980533468084939)\n",
      "('Loss of the ', 183, ' iteration for validation:', 17.352415497490661)\n",
      "('Loss of the ', 184, ' iteration for train:', 26.929048055760816)\n",
      "('Loss of the ', 184, ' iteration for validation:', 17.308023990442855)\n",
      "('Loss of the ', 185, ' iteration for train:', 26.877764210847129)\n",
      "('Loss of the ', 185, ' iteration for validation:', 17.263865136012409)\n",
      "('Loss of the ', 186, ' iteration for train:', 26.826680885657709)\n",
      "('Loss of the ', 186, ' iteration for validation:', 17.219937202121361)\n",
      "('Loss of the ', 187, ' iteration for train:', 26.775797045144834)\n",
      "('Loss of the ', 187, ' iteration for validation:', 17.176238478242514)\n",
      "('Loss of the ', 188, ' iteration for train:', 26.725111666564089)\n",
      "('Loss of the ', 188, ' iteration for validation:', 17.132767275073899)\n",
      "('Loss of the ', 189, ' iteration for train:', 26.674623739151269)\n",
      "('Loss of the ', 189, ' iteration for validation:', 17.089521924216609)\n",
      "('Loss of the ', 190, ' iteration for train:', 26.624332263810334)\n",
      "('Loss of the ', 190, ' iteration for validation:', 17.046500777855897)\n",
      "('Loss of the ', 191, ' iteration for train:', 26.574236252812192)\n",
      "('Loss of the ', 191, ' iteration for validation:', 17.003702208445805)\n",
      "('Loss of the ', 192, ' iteration for train:', 26.524334729503781)\n",
      "('Loss of the ', 192, ' iteration for validation:', 16.961124608397071)\n",
      "('Loss of the ', 193, ' iteration for train:', 26.474626728027104)\n",
      "('Loss of the ', 193, ' iteration for validation:', 16.91876638976872)\n",
      "('Loss of the ', 194, ' iteration for train:', 26.425111293047586)\n",
      "('Loss of the ', 194, ' iteration for validation:', 16.876625983963052)\n",
      "('Loss of the ', 195, ' iteration for train:', 26.375787479491702)\n",
      "('Loss of the ', 195, ' iteration for validation:', 16.834701841424216)\n",
      "('Loss of the ', 196, ' iteration for train:', 26.326654352293325)\n",
      "('Loss of the ', 196, ' iteration for validation:', 16.792992431340505)\n",
      "('Loss of the ', 197, ' iteration for train:', 26.277710986148321)\n",
      "('Loss of the ', 197, ' iteration for validation:', 16.751496241350143)\n",
      "('Loss of the ', 198, ' iteration for train:', 26.22895646527741)\n",
      "('Loss of the ', 198, ' iteration for validation:', 16.710211777250851)\n",
      "('Loss of the ', 199, ' iteration for train:', 26.180389883196657)\n",
      "('Loss of the ', 199, ' iteration for validation:', 16.669137562713065)\n",
      "('Loss of the ', 200, ' iteration for train:', 26.132010342495541)\n",
      "('Loss of the ', 200, ' iteration for validation:', 16.628272138996941)\n",
      "('Loss of the ', 201, ' iteration for train:', 26.083816954622112)\n",
      "('Loss of the ', 201, ' iteration for validation:', 16.587614064672941)\n",
      "('Loss of the ', 202, ' iteration for train:', 26.035808839675106)\n",
      "('Loss of the ', 202, ' iteration for validation:', 16.547161915346425)\n",
      "('Loss of the ', 203, ' iteration for train:', 25.987985126202727)\n",
      "('Loss of the ', 203, ' iteration for validation:', 16.506914283385743)\n",
      "('Loss of the ', 204, ' iteration for train:', 25.940344951007898)\n",
      "('Loss of the ', 204, ' iteration for validation:', 16.466869777654317)\n",
      "('Loss of the ', 205, ' iteration for train:', 25.892887458959599)\n",
      "('Loss of the ', 205, ' iteration for validation:', 16.427027023246392)\n",
      "('Loss of the ', 206, ' iteration for train:', 25.845611802810232)\n",
      "('Loss of the ', 206, ' iteration for validation:', 16.387384661226591)\n",
      "('Loss of the ', 207, ' iteration for train:', 25.798517143018771)\n",
      "('Loss of the ', 207, ' iteration for validation:', 16.347941348373269)\n",
      "('Loss of the ', 208, ' iteration for train:', 25.75160264757935)\n",
      "('Loss of the ', 208, ' iteration for validation:', 16.30869575692563)\n",
      "('Loss of the ', 209, ' iteration for train:', 25.704867491855357)\n",
      "('Loss of the ', 209, ' iteration for validation:', 16.269646574334658)\n",
      "('Loss of the ', 210, ' iteration for train:', 25.658310858418535)\n",
      "('Loss of the ', 210, ' iteration for validation:', 16.230792503017717)\n",
      "('Loss of the ', 211, ' iteration for train:', 25.611931936893189)\n",
      "('Loss of the ', 211, ' iteration for validation:', 16.192132260117003)\n",
      "('Loss of the ', 212, ' iteration for train:', 25.565729923805094)\n",
      "('Loss of the ', 212, ' iteration for validation:', 16.153664577261658)\n",
      "('Loss of the ', 213, ' iteration for train:', 25.519704022435192)\n",
      "('Loss of the ', 213, ' iteration for validation:', 16.115388200333619)\n",
      "('Loss of the ', 214, ' iteration for train:', 25.473853442677726)\n",
      "('Loss of the ', 214, ' iteration for validation:', 16.077301889237177)\n",
      "('Loss of the ', 215, ' iteration for train:', 25.428177400902502)\n",
      "('Loss of the ', 215, ' iteration for validation:', 16.039404417672163)\n",
      "('Loss of the ', 216, ' iteration for train:', 25.38267511982172)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss of the ', 216, ' iteration for validation:', 16.00169457291085)\n",
      "('Loss of the ', 217, ' iteration for train:', 25.337345828360561)\n",
      "('Loss of the ', 217, ' iteration for validation:', 15.964171155578402)\n",
      "('Loss of the ', 218, ' iteration for train:', 25.292188761531751)\n",
      "('Loss of the ', 218, ' iteration for validation:', 15.926832979436952)\n",
      "('Loss of the ', 219, ' iteration for train:', 25.247203160314019)\n",
      "('Loss of the ', 219, ' iteration for validation:', 15.889678871173274)\n",
      "('Loss of the ', 220, ' iteration for train:', 25.202388271534005)\n",
      "('Loss of the ', 220, ' iteration for validation:', 15.852707670189877)\n",
      "('Loss of the ', 221, ' iteration for train:', 25.157743347751882)\n",
      "('Loss of the ', 221, ' iteration for validation:', 15.815918228399731)\n",
      "('Loss of the ', 222, ' iteration for train:', 25.113267647150384)\n",
      "('Loss of the ', 222, ' iteration for validation:', 15.779309410024345)\n",
      "('Loss of the ', 223, ' iteration for train:', 25.068960433426891)\n",
      "('Loss of the ', 223, ' iteration for validation:', 15.742880091395348)\n",
      "('Loss of the ', 224, ' iteration for train:', 25.024820975689117)\n",
      "('Loss of the ', 224, ' iteration for validation:', 15.706629160759412)\n",
      "('Loss of the ', 225, ' iteration for train:', 24.98084854835346)\n",
      "('Loss of the ', 225, ' iteration for validation:', 15.670555518086545)\n",
      "('Loss of the ', 226, ' iteration for train:', 24.937042431046727)\n",
      "('Loss of the ', 226, ' iteration for validation:', 15.634658074881688)\n",
      "('Loss of the ', 227, ' iteration for train:', 24.893401908510437)\n",
      "('Loss of the ', 227, ' iteration for validation:', 15.598935753999603)\n",
      "('Loss of the ', 228, ' iteration for train:', 24.849926270508092)\n",
      "('Loss of the ', 228, ' iteration for validation:', 15.563387489462974)\n",
      "('Loss of the ', 229, ' iteration for train:', 24.806614811735145)\n",
      "('Loss of the ', 229, ' iteration for validation:', 15.528012226283726)\n",
      "('Loss of the ', 230, ' iteration for train:', 24.763466831731478)\n",
      "('Loss of the ', 230, ' iteration for validation:', 15.492808920287462)\n",
      "('Loss of the ', 231, ' iteration for train:', 24.720481634796556)\n",
      "('Loss of the ', 231, ' iteration for validation:', 15.457776537941028)\n",
      "('Loss of the ', 232, ' iteration for train:', 24.67765852990695)\n",
      "('Loss of the ', 232, ' iteration for validation:', 15.42291405618314)\n",
      "('Loss of the ', 233, ' iteration for train:', 24.63499683063618)\n",
      "('Loss of the ', 233, ' iteration for validation:', 15.388220462258046)\n",
      "('Loss of the ', 234, ' iteration for train:', 24.592495855077033)\n",
      "('Loss of the ', 234, ' iteration for validation:', 15.353694753552153)\n",
      "('Loss of the ', 235, ' iteration for train:', 24.550154925765842)\n",
      "('Loss of the ', 235, ' iteration for validation:', 15.319335937433603)\n",
      "('Loss of the ', 236, ' iteration for train:', 24.507973369609289)\n",
      "('Loss of the ', 236, ' iteration for validation:', 15.285143031094718)\n",
      "('Loss of the ', 237, ' iteration for train:', 24.465950517812804)\n",
      "('Loss of the ', 237, ' iteration for validation:', 15.251115061397332)\n",
      "('Loss of the ', 238, ' iteration for train:', 24.424085705811393)\n",
      "('Loss of the ', 238, ' iteration for validation:', 15.217251064720921)\n",
      "('Loss of the ', 239, ' iteration for train:', 24.382378273202288)\n",
      "('Loss of the ', 239, ' iteration for validation:', 15.183550086813478)\n",
      "('Loss of the ', 240, ' iteration for train:', 24.340827563679323)\n",
      "('Loss of the ', 240, ' iteration for validation:', 15.150011182645095)\n",
      "('Loss of the ', 241, ' iteration for train:', 24.299432924969448)\n",
      "('Loss of the ', 241, ' iteration for validation:', 15.116633416264305)\n",
      "('Loss of the ', 242, ' iteration for train:', 24.258193708770733)\n",
      "('Loss of the ', 242, ' iteration for validation:', 15.083415860656933)\n",
      "('Loss of the ', 243, ' iteration for train:', 24.217109270692244)\n",
      "('Loss of the ', 243, ' iteration for validation:', 15.050357597607649)\n",
      "('Loss of the ', 244, ' iteration for train:', 24.176178970195522)\n",
      "('Loss of the ', 244, ' iteration for validation:', 15.017457717564)\n",
      "('Loss of the ', 245, ' iteration for train:', 24.135402170537677)\n",
      "('Loss of the ', 245, ' iteration for validation:', 14.98471531950298)\n",
      "('Loss of the ', 246, ' iteration for train:', 24.094778238716088)\n",
      "('Loss of the ', 246, ' iteration for validation:', 14.952129510800043)\n",
      "('Loss of the ', 247, ' iteration for train:', 24.054306545414519)\n",
      "('Loss of the ', 247, ' iteration for validation:', 14.919699407100566)\n",
      "('Loss of the ', 248, ' iteration for train:', 24.013986464950783)\n",
      "('Loss of the ', 248, ' iteration for validation:', 14.887424132193646)\n",
      "('Loss of the ', 249, ' iteration for train:', 23.973817375225771)\n",
      "('Loss of the ', 249, ' iteration for validation:', 14.855302817888274)\n",
      "('Loss of the ', 250, ' iteration for train:', 23.933798657673819)\n",
      "('Loss of the ', 250, ' iteration for validation:', 14.823334603891801)\n",
      "('Loss of the ', 251, ' iteration for train:', 23.893929697214553)\n",
      "('Loss of the ', 251, ' iteration for validation:', 14.791518637690626)\n",
      "('Loss of the ', 252, ' iteration for train:', 23.854209882205836)\n",
      "('Loss of the ', 252, ' iteration for validation:', 14.759854074433164)\n",
      "('Loss of the ', 253, ' iteration for train:', 23.814638604398038)\n",
      "('Loss of the ', 253, ' iteration for validation:', 14.728340076814918)\n",
      "('Loss of the ', 254, ' iteration for train:', 23.775215258889531)\n",
      "('Loss of the ', 254, ' iteration for validation:', 14.696975814965741)\n",
      "('Loss of the ', 255, ' iteration for train:', 23.735939244083344)\n",
      "('Loss of the ', 255, ' iteration for validation:', 14.665760466339172)\n",
      "('Loss of the ', 256, ' iteration for train:', 23.696809961644956)\n",
      "('Loss of the ', 256, ' iteration for validation:', 14.634693215603848)\n",
      "('Loss of the ', 257, ' iteration for train:', 23.657826816461085)\n",
      "('Loss of the ', 257, ' iteration for validation:', 14.6037732545369)\n",
      "('Loss of the ', 258, ' iteration for train:', 23.618989216599747)\n",
      "('Loss of the ', 258, ' iteration for validation:', 14.572999781919416)\n",
      "('Loss of the ', 259, ' iteration for train:', 23.580296573271124)\n",
      "('Loss of the ', 259, ' iteration for validation:', 14.542372003433734)\n",
      "('Loss of the ', 260, ' iteration for train:', 23.541748300789568)\n",
      "('Loss of the ', 260, ' iteration for validation:', 14.511889131562766)\n",
      "('Loss of the ', 261, ' iteration for train:', 23.503343816536542)\n",
      "('Loss of the ', 261, ' iteration for validation:', 14.481550385491101)\n",
      "('Loss of the ', 262, ' iteration for train:', 23.465082540924463)\n",
      "('Loss of the ', 262, ' iteration for validation:', 14.451354991008023)\n",
      "('Loss of the ', 263, ' iteration for train:', 23.426963897361496)\n",
      "('Loss of the ', 263, ' iteration for validation:', 14.421302180412273)\n",
      "('Loss of the ', 264, ' iteration for train:', 23.388987312217175)\n",
      "('Loss of the ', 264, ' iteration for validation:', 14.391391192418638)\n",
      "('Loss of the ', 265, ' iteration for train:', 23.351152214789)\n",
      "('Loss of the ', 265, ' iteration for validation:', 14.361621272066214)\n",
      "('Loss of the ', 266, ' iteration for train:', 23.313458037269591)\n",
      "('Loss of the ', 266, ' iteration for validation:', 14.331991670628446)\n",
      "('Loss of the ', 267, ' iteration for train:', 23.275904214715052)\n",
      "('Loss of the ', 267, ' iteration for validation:', 14.302501645524769)\n",
      "('Loss of the ', 268, ' iteration for train:', 23.238490185013685)\n",
      "('Loss of the ', 268, ' iteration for validation:', 14.273150460233945)\n",
      "('Loss of the ', 269, ' iteration for train:', 23.201215388855747)\n",
      "('Loss of the ', 269, ' iteration for validation:', 14.243937384208976)\n",
      "('Loss of the ', 270, ' iteration for train:', 23.164079269703858)\n",
      "('Loss of the ', 270, ' iteration for validation:', 14.214861692793585)\n",
      "('Loss of the ', 271, ' iteration for train:', 23.127081273763963)\n",
      "('Loss of the ', 271, ' iteration for validation:', 14.185922667140265)\n",
      "('Loss of the ', 272, ' iteration for train:', 23.090220849957312)\n",
      "('Loss of the ', 272, ' iteration for validation:', 14.157119594129851)\n",
      "('Loss of the ', 273, ' iteration for train:', 23.053497449892763)\n",
      "('Loss of the ', 273, ' iteration for validation:', 14.12845176629255)\n",
      "('Loss of the ', 274, ' iteration for train:', 23.01691052783989)\n",
      "('Loss of the ', 274, ' iteration for validation:', 14.099918481730416)\n",
      "('Loss of the ', 275, ' iteration for train:', 22.980459540702729)\n",
      "('Loss of the ', 275, ' iteration for validation:', 14.071519044041306)\n",
      "('Loss of the ', 276, ' iteration for train:', 22.944143947994082)\n",
      "('Loss of the ', 276, ' iteration for validation:', 14.043252762244222)\n",
      "('Loss of the ', 277, ' iteration for train:', 22.907963211810429)\n",
      "('Loss of the ', 277, ' iteration for validation:', 14.015118950705943)\n",
      "('Loss of the ', 278, ' iteration for train:', 22.871916796807383)\n",
      "('Loss of the ', 278, ' iteration for validation:', 13.987116929069121)\n",
      "('Loss of the ', 279, ' iteration for train:', 22.836004170175734)\n",
      "('Loss of the ', 279, ' iteration for validation:', 13.959246022181636)\n",
      "('Loss of the ', 280, ' iteration for train:', 22.800224801617997)\n",
      "('Loss of the ', 280, ' iteration for validation:', 13.931505560027224)\n",
      "('Loss of the ', 281, ' iteration for train:', 22.764578163325453)\n",
      "('Loss of the ', 281, ' iteration for validation:', 13.903894877657414)\n",
      "('Loss of the ', 282, ' iteration for train:', 22.729063729955797)\n",
      "('Loss of the ', 282, ' iteration for validation:', 13.87641331512469)\n",
      "('Loss of the ', 283, ' iteration for train:', 22.693680978611226)\n",
      "('Loss of the ', 283, ' iteration for validation:', 13.849060217416863)\n",
      "('Loss of the ', 284, ' iteration for train:', 22.658429388816828)\n",
      "('Loss of the ', 284, ' iteration for validation:', 13.821834934392633)\n",
      "('Loss of the ', 285, ' iteration for train:', 22.623308442499766)\n",
      "('Loss of the ', 285, ' iteration for validation:', 13.794736820718324)\n",
      "('Loss of the ', 286, ' iteration for train:', 22.588317623968614)\n",
      "('Loss of the ', 286, ' iteration for validation:', 13.76776523580579)\n",
      "('Loss of the ', 287, ' iteration for train:', 22.553456419893255)\n",
      "('Loss of the ', 287, ' iteration for validation:', 13.740919543751396)\n",
      "('Loss of the ', 288, ' iteration for train:', 22.518724319285219)\n",
      "('Loss of the ', 288, ' iteration for validation:', 13.714199113276139)\n",
      "('Loss of the ', 289, ' iteration for train:', 22.484120813478306)\n",
      "('Loss of the ', 289, ' iteration for validation:', 13.687603317666802)\n",
      "('Loss of the ', 290, ' iteration for train:', 22.449645396109776)\n",
      "('Loss of the ', 290, ' iteration for validation:', 13.661131534718239)\n",
      "('Loss of the ', 291, ' iteration for train:', 22.415297563101753)\n",
      "('Loss of the ', 291, ' iteration for validation:', 13.6347831466766)\n",
      "('Loss of the ', 292, ' iteration for train:', 22.381076812643109)\n",
      "('Loss of the ', 292, ' iteration for validation:', 13.608557540183646)\n",
      "('Loss of the ', 293, ' iteration for train:', 22.346982645171682)\n",
      "('Loss of the ', 293, ' iteration for validation:', 13.582454106222041)\n",
      "('Loss of the ', 294, ' iteration for train:', 22.313014563356813)\n",
      "('Loss of the ', 294, ' iteration for validation:', 13.556472240061558)\n",
      "('Loss of the ', 295, ' iteration for train:', 22.279172072082279)\n",
      "('Loss of the ', 295, ' iteration for validation:', 13.530611341206354)\n",
      "('Loss of the ', 296, ' iteration for train:', 22.245454678429503)\n",
      "('Loss of the ', 296, ' iteration for validation:', 13.504870813343079)\n",
      "('Loss of the ', 297, ' iteration for train:', 22.211861891661083)\n",
      "('Loss of the ', 297, ' iteration for validation:', 13.479250064289928)\n",
      "('Loss of the ', 298, ' iteration for train:', 22.17839322320469)\n",
      "('Loss of the ', 298, ' iteration for validation:', 13.453748505946631)\n",
      "('Loss of the ', 299, ' iteration for train:', 22.145048186637204)\n",
      "('Loss of the ', 299, ' iteration for validation:', 13.428365554245273)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl4VfW99/33dw/JzkQSkpAAQRlE\nASdARKxj1Vq0tqjF6bRWqJbWQ6u2d9uHnnOetnrbu57WY1vPsfjoVVv1autsq721VikWbZ2AAjKo\nIILMhAAJSUiyd/J7/lgrYSfshEw7O2F/Xte1r7XWbw37u9jKhzX9ljnnEBERaS+Q6gJERGRgUkCI\niEhCCggREUlIASEiIgkpIEREJCEFhIiIJKSAEBGRhBQQIl1gZpvM7KJU1yHSnxQQIiKSkAJCpBfM\n7CtmtsHM9prZc2Y2wm83M/uZme02s2oze9fMTvLnXWpma83sgJltM7Nvp3YvRBJTQIj0kJldAPwY\nuBoYDmwGHvNnXwycCxwP5PvLVPrzfgV81TmXB5wE/LUfyxbpslCqCxAZxL4APOScWw5gZt8D9pnZ\naCAK5AETgLedc+vi1osCk8xspXNuH7CvX6sW6SIdQYj03Ai8owYAnHM1eEcJI51zfwX+B7gP2G1m\nD5jZEH/RzwOXApvN7G9mdmY/1y3SJQoIkZ7bDhzbMmFmOUARsA3AOXevc+40YBLeqabv+O3vOOdm\nAcOAPwBP9HPdIl2igBDpurCZRVo+wO+BuWY22cwygf8DvOWc22Rmp5vZGWYWBmqBeqDZzDLM7Atm\nlu+ciwLVQHPK9kikEwoIka57ATgY9zkf+H+Bp4EdwDjgWn/ZIcCDeNcXNuOdevqpP+96YJOZVQNf\nw7uWITLgmF4YJCIiiegIQkREElJAiIhIQgoIERFJSAEhIiIJDeonqYuLi93o0aNTXYaIyKCybNmy\nPc65kiMtN6gDYvTo0SxdujTVZYiIDCpmtvnIS+kUk4iIdEABISIiCSkgREQkoUF9DUJE+k80GmXr\n1q3U19enuhTpokgkQnl5OeFwuEfrKyBEpEu2bt1KXl4eo0ePxsxSXY4cgXOOyspKtm7dypgxY3q0\nDZ1iEpEuqa+vp6ioSOEwSJgZRUVFvTriU0CISJcpHAaX3v5eaRkQ7+2s5u6X3mdvbWOqSxERGbCS\nFhD+S1XeNrOVZrbGzG7328eY2VtmtsHMHjezDL8905/e4M8fnazaNu2p5X8Wb2BnlS62iYh0JJlH\nEA3ABc65U4HJwEwzmwH8J/Az59xxeC9TudFf/kZgn9/+M3+5pBgS8a7oV9dHk/UVItLH9u/fzy9/\n+ctur3fppZeyf//+Tpf5/ve/zyuvvNLT0hLKzc3t0+2lQtICwnlq/Mmw/3HABcBTfvvDwOX++Cx/\nGn/+hZakE55DsvyAOKiAEBksOgqIWCzW6XovvPACBQUFnS5zxx13cNFFF/WqvqNRUm9zNbMgsAw4\nDrgP+BDY75xr+UW3AiP98ZHAFgDnXMzMqvBeAL+n3TbnAfMAjjnmmB7V1XIEUaWAEOmR259fw9rt\n1X26zUkjhvCDz57Y4fwFCxbw4YcfMnnyZMLhMJFIhMLCQt577z0++OADLr/8crZs2UJ9fT233nor\n8+bNAw712VZTU8Mll1zC2WefzT/+8Q9GjhzJH//4R7KyspgzZw6XXXYZs2fPZvTo0dxwww08//zz\nRKNRnnzySSZMmEBFRQX/8i//wvbt2znzzDN5+eWXWbZsGcXFxZ3ul3OO7373u7z44ouYGf/xH//B\nNddcw44dO7jmmmuorq4mFouxcOFCPvGJT3DjjTeydOlSzIwvf/nLfPOb3+zTP+fuSOpFaudck3Nu\nMlAOTAcm9ME2H3DOTXPOTSspOWJnhAkNyfJysbq+8395iMjAcddddzFu3DhWrFjBT3/6U5YvX84v\nfvELPvjgAwAeeughli1bxtKlS7n33nuprKw8bBvr169n/vz5rFmzhoKCAp5++umE31VcXMzy5cu5\n+eabufvuuwG4/fbbueCCC1izZg2zZ8/m448/7lLdzzzzDCtWrGDlypW88sorfOc732HHjh387ne/\n49Of/nTrvMmTJ7NixQq2bdvG6tWreffdd5k7d24P/7T6Rr88KOec229mi4EzgQIzC/lHEeXANn+x\nbcAoYKuZhYB8vBe997ncTD8gdAQh0iOd/Uu/v0yfPr3NA2D33nsvzz77LABbtmxh/fr1FBUVtVln\nzJgxTJ48GYDTTjuNTZs2Jdz2lVde2brMM888A8Drr7/euv2ZM2dSWFjYpTpff/11rrvuOoLBIKWl\npZx33nm88847nH766Xz5y18mGo1y+eWXM3nyZMaOHcvGjRv5xje+wWc+8xkuvvjirv+BJEEy72Iq\nMbMCfzwL+BSwDlgMzPYXuwH4oz/+nD+NP/+vzjmXjNpCwQC5mSFdpBYZxHJyclrHX331VV555RXe\neOMNVq5cyZQpUxI+IJaZmdk6HgwGO7x+0bJcZ8v01rnnnsuSJUsYOXIkc+bM4ZFHHqGwsJCVK1dy\n/vnnc//993PTTTcl5bu7KpmnmIYDi81sFfAO8LJz7k/A/wN8y8w24F1j+JW//K+AIr/9W8CCJNbG\nkEiI6oM6xSQyWOTl5XHgwIGE86qqqigsLCQ7O5v33nuPN998s8+//6yzzuKJJ54A4C9/+Qv79u3r\n0nrnnHMOjz/+OE1NTVRUVLBkyRKmT5/O5s2bKS0t5Stf+Qo33XQTy5cvZ8+ePTQ3N/P5z3+eO++8\nk+XLl/f5fnRH0k4xOedWAVMStG/Eux7Rvr0euCpZ9bQ3JCusIwiRQaSoqIizzjqLk046iaysLEpL\nS1vnzZw5k/vvv5+JEydywgknMGPGjD7//h/84Adcd911PProo5x55pmUlZWRl5d3xPWuuOIK3njj\nDU499VTMjJ/85CeUlZXx8MMP89Of/pRwOExubi6PPPII27ZtY+7cuTQ3NwPw4x//uM/3ozssSWdx\n+sW0adNcT98od/X9b2AGj3/1zD6uSuTotG7dOiZOnJjqMlKmoaGBYDBIKBTijTfe4Oabb2bFihWp\nLuuIEv1uZrbMOTftSOumbW+uQ7LCbNt/MNVliMgg8fHHH3P11VfT3NxMRkYGDz74YKpLSro0DogQ\n63boFJOIdM348eP55z//2aatsrKSCy+88LBlFy1adNgdVINR+gZERNcgRKR3ioqKBsVppp5Ky95c\nwTvFVNMQo7l58F6DERFJpvQNiEgI5+BAg251FRFJJH0DQh32iYh0Kn0DQl1+i4h0Kn0DoqXDPj1N\nLXLUanknw/bt25k9e3bCZc4//3yO9DzVz3/+c+rq6lqnu/KOie6YM2cOTz311JEX7GfpGxA6ghBJ\nGyNGjOjVX8DtA6Ir75g4GqTtba75ugYh0nMvLoCd7/btNstOhkvu6nSRBQsWMGrUKObPnw/AD3/4\nQ0KhEIsXL2bfvn1Eo1HuvPNOZs2a1Wa9TZs2cdlll7F69WoOHjzI3LlzWblyJRMmTODgwUMPzN58\n88288847HDx4kNmzZ3P77bdz7733sn37dj75yU9SXFzM4sWLW98xUVxczD333MNDDz0EwE033cRt\nt93Gpk2bOnz3xJEsWrSIb3/728RiMU4//XQWLlxIZmYmCxYs4LnnniMUCnHxxRdz99138+STT3L7\n7bcTDAbJz89nyZIl3f1T71R6BkTlhxSveZEhDNM7IUQGkWuuuYbbbrutNSCeeOIJXnrpJW655RaG\nDBnCnj17mDFjBp/73Ofo6IWUCxcuJDs7m3Xr1rFq1SqmTp3aOu9HP/oRQ4cOpampiQsvvJBVq1Zx\nyy23cM8997B48eLDXg60bNkyfv3rX/PWW2/hnOOMM87gvPPOo7CwkPXr1/P73/+eBx98kKuvvpqn\nn36aL37xi53uX319PXPmzGHRokUcf/zxfOlLX2LhwoVcf/31PPvss7z33nuYWevprTvuuIOXXnqJ\nkSNH9ukprxbpGRC7VpP1139npP1YRxAiPXGEf+kny5QpU9i9ezfbt2+noqKCwsJCysrK+OY3v8mS\nJUsIBAJs27aNXbt2UVZWlnAbS5Ys4ZZbbgHglFNO4ZRTTmmd98QTT/DAAw8Qi8XYsWMHa9eubTO/\nvddff50rrriitevxK6+8ktdee43Pfe5zXX73RLz333+fMWPGcPzxxwNwww03cN999/H1r3+dSCTC\njTfeyGWXXcZll10GeD3Mzpkzh6uvvrr1HRZ9KT2vQUS8c4dlGfW6BiEyyFx11VU89dRTPP7441xz\nzTX89re/paKigmXLlrFixQpKS0sTvgviSD766CPuvvtuFi1axKpVq/jMZz7To+206Oq7J7oiFArx\n9ttvM3v2bP70pz8xc+ZMAO6//37uvPNOtmzZwmmnnZbwLXq9kZ4BkeW9Caoso153MYkMMtdccw2P\nPfYYTz31FFdddRVVVVUMGzaMcDjM4sWL2bx5c6frn3vuufzud78DYPXq1axatQqA6upqcnJyyM/P\nZ9euXbz44out63T0LopzzjmHP/zhD9TV1VFbW8uzzz7LOeec0+N9O+GEE9i0aRMbNmwA4NFHH+W8\n886jpqaGqqoqLr30Un72s5+xcuVKAD788EPOOOMM7rjjDkpKStiyZUuPvzuR9DzFlOUdQZSEDrJO\nRxAig8qJJ57IgQMHGDlyJMOHD+cLX/gCn/3sZzn55JOZNm0aEyZM6HT9m2++mblz5zJx4kQmTpzI\naaedBsCpp57KlClTmDBhAqNGjeKss85qXWfevHnMnDmTESNGsHjx4tb2qVOnMmfOHKZP915xc9NN\nNzFlypQunU5KJBKJ8Otf/5qrrrqq9SL11772Nfbu3cusWbOor6/HOcc999wDwHe+8x3Wr1+Pc44L\nL7yQU089tUff25H0fB9EfTXcNYpH827iT7mz9U4IkS5I9/dBDFa9eR9Eep5iyswDCzI0WEeVLlKL\niCSUnqeYzCCrgAKr44CuQYhIP5k/fz5///vf27TdeuutzJ07N0UVdS49AwIgUkC+O6DbXEW6wTnX\n4fMFcmT33Xdfv35fby8hpOcpJoCsAnJdLQcaYjTpnRAiRxSJRKisrOz1XzrSP5xzVFZWEolEeryN\n9D2CyCok58AOAGrqY+Rnh1NckMjAVl5eztatW6moqEh1KdJFkUiE8vLyHq+fvgERKSAS+wDwOuxT\nQIh0LhwOM2bMmFSXIf0orU8xZcaqAXQnk4hIAukbEJECwtFqjGb21ykgRETaS1pAmNkoM1tsZmvN\nbI2Z3eq3/9DMtpnZCv9zadw63zOzDWb2vpl9Olm1AZBViLlmcqlnb11jUr9KRGQwSuY1iBjwv5xz\ny80sD1hmZi/7837mnLs7fmEzmwRcC5wIjABeMbPjnXNNSanO724j32rZr4AQETlM0o4gnHM7nHPL\n/fEDwDpgZCerzAIec841OOc+AjYA05NVX0uPrvnUsLdWASEi0l6/XIMws9HAFOAtv+nrZrbKzB4y\ns0K/bSQQ3xXhVhIEipnNM7OlZra0V7fb+UcQIzLrdQ1CRCSBpAeEmeUCTwO3OeeqgYXAOGAysAP4\nr+5szzn3gHNumnNuWklJSc8L87v8Hp7ZoCMIEZEEkhoQZhbGC4ffOueeAXDO7XLONTnnmoEHOXQa\naRswKm71cr8tOfxTTKXhevbpGoSIyGGSeReTAb8C1jnn7olrHx632BXAan/8OeBaM8s0szHAeODt\nZNXXcoppWKhWASEikkAy72I6C7geeNfMVvht/wZcZ2aTAQdsAr4K4JxbY2ZPAGvx7oCan7Q7mADC\n2RAIMzR4kH21ugYhItJe0gLCOfc6kKjbxxc6WedHwI+SVVMbZpBVSKHpCEJEJJH0fZIaIKuAIVZL\nXWMT9dHkHayIiAxG6R0QkQJym70XketWVxGRttI7ILIKyGryAkK3uoqItJXmAVFIZswLCF2HEBFp\nK70DIlJAuLEKUECIiLSX3gGRVUCwsZoAzezTKSYRkTbSOyD8p6nzqGOfLlKLiLSR3gHh98c0IrNe\nF6lFRNpRQADHROr1TggRkXbSOyCyiwAYmVnHXp1iEhFpI70DIscLiOHhWl2kFhFpJ70DIrsYgGHB\nGt3mKiLSTnoHRGYeBDMotgM6ghARaSe9A8IMsosppIraxiYaYuqwT0SkRXoHBEBOEUOavaep1WGf\niMghCojsYnJj+wF12CciEk8BkVNMJLoPUECIiMRTQGQXk9GwF4A9NQ0pLkZEZOBQQOQUEYjWkkkj\nFQcUECIiLRQQOSUAlIZqFBAiInEUEP7DcuOy6xUQIiJxFBA5XkAcm3WQCl2DEBFppYDwjyDKM2p1\nBCEiEkcB4XfYVxaq1V1MIiJxFBCRAgiEGBaoprK2kVhTc6orEhEZEJIWEGY2yswWm9laM1tjZrf6\n7UPN7GUzW+8PC/12M7N7zWyDma0ys6nJqq1doZBdRKFV45welhMRaZHMI4gY8L+cc5OAGcB8M5sE\nLAAWOefGA4v8aYBLgPH+Zx6wMIm1tZVdzJAmrz+m3boOISICJDEgnHM7nHPL/fEDwDpgJDALeNhf\n7GHgcn98FvCI87wJFJjZ8GTV10ZOETl+f0y6k0lExNMv1yDMbDQwBXgLKHXO7fBn7QRK/fGRwJa4\n1bb6be23Nc/MlprZ0oqKir4pMLuYzEavPybdySQi4kl6QJhZLvA0cJtzrjp+nnPOAa4723POPeCc\nm+acm1ZSUtI3ReYUE6qvBBQQIiItkhoQZhbGC4ffOuee8Zt3tZw68oe7/fZtwKi41cv9tuTLLsYa\nqinMVECIiLRI5l1MBvwKWOecuydu1nPADf74DcAf49q/5N/NNAOoijsVlVz+sxDH5dTrGoSIiC+U\nxG2fBVwPvGtmK/y2fwPuAp4wsxuBzcDV/rwXgEuBDUAdMDeJtbXld9g3Oruej3UEISICJDEgnHOv\nA9bB7AsTLO+A+cmqp1N+QBybeYBl1QoIERHQk9SevDIAykPVugYhIuJTQADkegFRGtjPgfoY9dGm\nFBckIpJ6CgiAjGzIzKe4Wc9CiIi0UEC0yCsjv2kPoKepRURAAXFIXhm5jd7Dcruq6lNcjIhI6ikg\nWuQNJ7Pee2ZvuwJCREQB0SqvjEDNTjJDxo79B1NdjYhIyikgWuSVYc1RJuTH2KEjCBERBUQr/1mI\nibm1bK/SEYSIiAKiRZ736omxkRp27NcRhIiIAqKFfwRxbKiK3Qfq9W5qEUl7CogW/tPUZcH9NDvY\npYflRCTNKSBahCMQKaDYeU9T604mEUl3Coh4ecMZEvOept6mgBCRNNelgDCzcWaW6Y+fb2a3mFlB\ncktLgbwyshu891zrVlcRSXddPYJ4Gmgys+OAB/BeDfq7pFWVKnnDCdbsIi8zpFNMIpL2uhoQzc65\nGHAF8N/Oue8Aw5NXVorklUHNLkbmZ6q7DRFJe10NiKiZXYf3Duk/+W3h5JSUQnll0Bxl/JBGduhh\nORFJc10NiLnAmcCPnHMfmdkY4NHklZUi/rMQx2XpYTkRkS69k9o5txa4BcDMCoE859x/JrOwlMgb\nAcDYjCoqazOpjzYRCQdTXJSISGp09S6mV81siJkNBZYDD5rZPcktLQXyywEYGfDeC7FT1yFEJI11\n9RRTvnOuGrgSeMQ5dwZwUfLKSpHcUghmUNq0C4DtupNJRNJYVwMiZGbDgas5dJH66BMIQH45BVEv\nILbuU0CISPrqakDcAbwEfOice8fMxgLrk1dWChUcQ3bdNkIBY1NlbaqrERFJma5epH4SeDJueiPw\n+WQVlVL5o7D1f6G8MIvNe+tSXY2ISMp09SJ1uZk9a2a7/c/TZlZ+hHUe8pddHdf2QzPbZmYr/M+l\ncfO+Z2YbzOx9M/t0z3eplwqOhZpdHDc0zGYdQYhIGuvqKaZfA88BI/zP835bZ34DzEzQ/jPn3GT/\n8wKAmU0CrgVO9Nf5pZml5v7SglEAnJxbzebKOpxzKSlDRCTVuhoQJc65XzvnYv7nN0BJZys455YA\ne7u4/VnAY865BufcR8AGYHoX1+1bBccAcEJkHwfqY+yri6akDBGRVOtqQFSa2RfNLOh/vghU9vA7\nv25mq/xTUIV+20hgS9wyW/22w5jZPDNbamZLKyoqelhCJ/K9I4hj/GchdKFaRNJVVwPiy3i3uO4E\ndgCzgTk9+L6FwDhgsr+d/+ruBpxzDzjnpjnnppWUdHoQ0zN5wyEQosztBuDjSl2oFpH01KWAcM5t\nds59zjlX4pwb5py7nB7cxeSc2+Wca3LONQMPcug00ja8LsRblPtt/S8YgiEjyG/ciZmOIEQkffXm\njXLf6u4K/sN2La4AWu5weg641swy/Y4AxwNv96K23ik4lmDVFoYPiegIQkTSVpeeg+iAdTrT7PfA\n+UCxmW0FfgCcb2aTAQdsAr4K4JxbY2ZPAGuBGDDfOdfUi9p6p+AY2PgqxxRl6whCRNJWbwKi0/s/\nnXPXJWj+VSfL/wj4US/q6Tv5o6B6O+NGZfDS+129EUtE5OjSaUCY2QESB4EBWUmpaCAoOAZwTMw9\nwG9rGjlQHyUvcvS9H0lEpDOdBoRzLq+/ChlQ/IflxmfsAzLYXFnHSSPzU1uTiEg/681F6qNX4RgA\nRrEDgM26UC0iaUgBkciQkRCKUNK4FTNYv/tAqisSEel3CohEAgEYOo7wvg85Zmg263fVpLoiEZF+\np4DoSPFxULmB8cPyeH+XjiBEJP0oIDpSdBzs28SEkgib9tTSGGtOdUUiIv1KAdGRovHQHGPykCpi\nzY6P9uiBORFJLwqIjhQdB8DxQe/91DrNJCLpRgHRkaJxAAyPbSFgsF4BISJpRgHRkeyhkF1EeP9G\nRhfn8IECQkTSjAKiM0XjYc8Gjh+Wxwe61VVE0owCojNF3q2ux5fmsrmylvpo6jqYFRHpbwqIzhQf\nBzU7mTA0QLODDyt0FCEi6UMB0Rn/TqYTI97rR9/fqesQIpI+FBCdKRoPQHlsC5FwgHe3VaW4IBGR\n/qOA6EzROAhmEKxYy4kj8nl3qwJCRNKHAqIzwTCUTICdqzmlPJ/V26uINanLDRFJDwqIIyk7GXat\n5tTyAuqjzazfrQvVIpIeFBBHUnoS1Oxi8tAoAKu27k9xQSIi/UMBcSSlJwJwTONG8jJDrNR1CBFJ\nEwqIIyk7GYDA7tWcXK4L1SKSPhQQR5I9FPJGwK7VnFJewHs7q2mI6YlqETn6KSC6ouyk1juZok2O\ndTv0wJyIHP0UEF1RehLseZ9Th2cBsOLjfSkuSEQk+ZIWEGb2kJntNrPVcW1DzexlM1vvDwv9djOz\ne81sg5mtMrOpyaqrR8pOguYYI6KbGVmQxVsf7U11RSIiSZfMI4jfADPbtS0AFjnnxgOL/GmAS4Dx\n/mcesDCJdXVfqXeh2na+yxljh/LWR3tpbnYpLkpEJLmSFhDOuSVA+39qzwIe9scfBi6Pa3/Eed4E\nCsxseLJq67ai4yAzH7YuZcbYIvbWNuqBORE56vX3NYhS59wOf3wnUOqPjwS2xC231W87jJnNM7Ol\nZra0oqIieZXGCwSgfBpseZszxxYB8ObGyv75bhGRFEnZRWrnnAO6fZ7GOfeAc26ac25aSUlJEirr\nwKjpsHsto7JjjCzIUkCIyFGvvwNiV8upI3+422/fBoyKW67cbxs4yk8HHGxbxoyxRby5sVLXIUTk\nqNbfAfEccIM/fgPwx7j2L/l3M80AquJORQ0M5dMAgy1vM2PsUPbVRflgt56HEJGjVzJvc/098AZw\ngpltNbMbgbuAT5nZeuAifxrgBWAjsAF4EPjXZNXVY5F8GDYRtr7NDP86xD826DSTiBy9QsnasHPu\nug5mXZhgWQfMT1Ytfab8dFjzB0YVRBhXksNf39vNl88ek+qqRESSQk9Sd8eoM6ChCvZ8wEWTSnlz\nYyXV9dFUVyUikhQKiO4YNd0bbnmTT00sJdbs+Nv7/XSrrYhIP1NAdEfRcZBbBhv/xpRjChmak8Er\n63aluioRkaRQQHSHGYy7ADYuJkgzF0wYxuL3dhPVe6pF5CikgOiucRfAwX2wYyWfmlRKdX2Md9R5\nn4gchRQQ3TX2fG/44V85Z3wxkXCA//vuwHpkQ0SkLygguiu3BMpOgQ8Xk50R4uJJZfxp1Q69ZU5E\njjoKiJ4Y90nY8hY01PD508qpOhhl0brdR15PRGQQUUD0xLgLoDkKm17n7OOKKR2SydPLtqa6KhGR\nPqWA6IlRMyAjFz54kWDAuHzKSF79oIKKAw2prkxEpM8oIHoiHIHjPw3rnoemGLOnltPU7PjDPwdW\nB7QiIr2hgOipSZdDXSVseo3xpXlMO7aQh9/YREzPRIjIUUIB0VPjPwXhHFj7BwBuOmcsW/cd5KU1\nerJaRI4OCoieCmfBCTNbTzN9alIpxxZl8+BrG/E6pxURGdwUEL0Rd5opGDBuPHsMK7bsZ9nmfamu\nTESk1xQQvTH+U5CRBysfA2D2aeUUZof5xaL1KS5MRKT3FBC9Ec6CU66GNc9C3V6yM0LM/+RxvLZ+\nD6+tVzfgIjK4KSB6a9pcaGpoPYq4/sxjKS/M4scvvEdzs65FiMjgpYDorbKToXw6LH0InCMzFOQ7\nnz6BtTuq+cMKPRchIoOXAqIvTJsLleth898B+OwpIzh1VAE/+r/rqKzR09UiMjgpIPrCiVdAViH8\n478BCASMn3z+FKrro/zw+bUpLk5EpGcUEH0hnAUz5sMHf4YdKwE4oSyPb1wwnudXbufPq3emuEAR\nke5TQPSVM+ZBZj787SetTTefP46TRg7hu0+tZNOe2hQWJyLSfQqIvhLJhxk3w3t/gp2rAQgHAyz8\nwmkEAsZXH11GbUMsxUWKiHSdAqIvzfgaZA6BV34Afncbo4Zm8z/XTWX97gPc+tgKourMT0QGiZQE\nhJltMrN3zWyFmS3124aa2ctmtt4fFqaitl7JKoTzF8CGV+D9F1qbzx5fzO2fO5FX1u3iW0+spEnP\nR4jIIJDKI4hPOucmO+em+dMLgEXOufHAIn968Jk+D0omwosLoLGutfn6M0fzvUsm8PzK7XzriRV6\nh7WIDHgD6RTTLOBhf/xh4PJrjBkSAAARFklEQVQU1tJzwTB85m6o+hiW/KTNrK+eN47vzjyBP67Y\nzg0PvU1VXTRFRYqIHFmqAsIBfzGzZWY2z28rdc7t8Md3AqWJVjSzeWa21MyWVlQM0P6ORp8NU74I\nr/8cPnqtzax/Pf84fnHtZJZv3s9n/+d1VmzZn6IiRUQ6l6qAONs5NxW4BJhvZufGz3TeCxUSnqh3\nzj3gnJvmnJtWUlLSD6X20Mz/hKJx8MxXoLayzaxZk0fy+3ln0NTsmL3wH/zilfU65SQiA05KAsI5\nt80f7gaeBaYDu8xsOIA/3J2K2vpMZi7Mfsh7X8TTN0JT29NJpx07lBduPYdLTh7Oz175gJk/f43F\n7+3Wy4ZEZMDo94Awsxwzy2sZBy4GVgPPATf4i90A/LG/a+tzw0+Fz9wDGxfD87e13vraIj8rzH9f\nN4XfzD0d5xxzf/MOs+9/g1ff362eYEUk5UIp+M5S4Fkza/n+3znn/mxm7wBPmNmNwGbg6hTU1vem\nXg/7/QvWucPgwu+Dt++tzj9hGH/5ZjFPLN3CfYs3MOfX7zC6KJsvnHGs9xKinIwUFS8i6cwG8ymN\nadOmuaVLl6a6jCNzDp6/FZY/DGfcDJ/+PxBIfPDWEGviz6t38ugbm1m6eR+hgHHmuCIuOWk4F00a\nxrC8SD8XLyJHGzNbFveIQcfLKSD6SXMz/OXf4c1fwslXw2d/ARnZna6yzn+nxJ9X72RzpfdMxXHD\ncjljzFBmjC1i+pihlA5RYIhI9yggBiLn4LX/gr/eCaUnwtWPeHc6HXE1x/u7DrD4vQre+qiSpZv2\nUeP361Scm8HE4UOYNGIIE8uGMKY4h9FFOeRnh5O9NyIySCkgBrL1L8PTN0FTI1z4A5j+FQgEu7x6\nrKmZNdurWf7xPtZur2btjmrW76qhMa6fp8LsMKOLczh2aDZl+VkMz49QOiRCWX6EsiERSvIyCQas\nk28RkaOVAmKg278F/nSb12/TiKlw8f/2HrDrocZYM5sqa9m0p9YbVtaxaU8tmyvr2H2gnmhT2985\nYFCSl0lRTiZDczJaP4XZGQzNzWBodgaFOWGKcjLJzwozJCtEVjiImUJFZLBTQAwGzsG7T8IrP4Tq\nbTDuAjhzPoy78LA7nXqjudmxt66RnVX13qe6nl3V3vi+ukYqaxvZV9vI3tpGqus77pI8FDCGZIUZ\nEgn5Qy84vOHh7bmZYXIzQ+RmhsjJDJKTGSIzFFDIiKSYAmIwiR6Et/4/7wJ2zS4oPgFOvwlOvNy7\nNbY/S2lqZl9dI/tqo1TWNnihcTBGdX2U6oNRfxg/HWttr48euSvzcNDIyQyRk3EoOHIjYXIzg+Rk\nhMjJDJEX8YY5maHW9txIy/LeMCsjSHY4SCg4kLoTExkcFBCDUawR1jzrBcWOFWAB77TTxM95RxdD\nx/bpkUVfa4g1caA1MGLU1MeoaYhS09BEbUOMmoZY67BlvLahqc10y7CrzwlmhAJkZ3ghkpURJLv1\n403ntBvPygi1WSY7I+jPazseCetIR45eCojBbtdaWPMMrH4G9n7otRUcA6PPhZFTvc+wEyF09D1E\n55zjYLTJD4tD4VJTH6O20Rs/2NhEXWMTtY2HxusaY/7w0PjBRm/9g9Gmw67DdMYMssKHQqR98ETC\nQbLCAbLCQSIZQW8Y9oYtbZFQgKy4eZFwsHU6KxwkMxQgoBsFJAUUEEcL56DyQ6+7jo2vwua/w8F9\n3rxgJpROguLjoXg8FI33hkPHQVjPR7TXGGv2wiTqBc/BDkLFC5YYte3GD/qBVB9tpj7qTR+MNlEf\nbaIh1rM3BWbGhUhWOEhmS/C0DxY/XLzpQOvyWRlBMkP+vFCATD94Iv4wflyn46SFAuJo5Rzs3wzb\nlsP25bDzXdizAaq3tl0uZxjkj4QhIyF/1KHx3GGQU+J9IgUdPtEt3dPc7KiPeaFR7wdRffRQgMSH\nSX20mYN+W3300HIHo956DbFDyx+MNtEQt/zBaM97/Q0GrMMQyWwd9wIoMxQkMxwg4g/jl490Y9nM\nkI6UBqKuBkQq+mKS3jCDwtHe56QrD7U31kLlBtiz3jviqN4KVdu86Y2vQmNNgm0FIbvID4xib5hV\nCFkFXnh0NMzIGdDXQlIhEDD/dFRy/5dyztEQa44Ln+bW4GiIeWHSEPPaG2JNrct67c2tRzvxy7QM\naxpi7KlpbLOdlvUae/ku9YxgSxAFyAgGyAgd+mSGgoe3xU8H45Y7wjKHtul9MoJt18kIBggHTdeX\nukgBcbTIyPF6jx1+6uHznIP6KqjeDrUV/mfP4ePblnmnr+qr6OB1HJ5AGCL5fmDkQ2YeZORC5hBv\nvPWToC1+uVCmgqabzKz1tFNBP35vU7OjsYOA6SiEOlq2MeaHTqyJRj98GmPN1NXFWsOo0V+usamZ\nhqg37Kt3uZtBOOgFTKLAOjQdbA221nAJGeFgS9D4n5C1TmeEWtoPtYVD7aaDh2/v0DaNYGDgBJgC\nIh2YeX+ZZ3Xxr5TmZmiohvr9cHB/58OGA96nZrc/Xu0NXRf+xRkIHx4eGTltP+Fsvz3bn87pfJlw\ntkInCYIB866LZHT9if++1hJSjbFmGpqa2oTIodCJG48PmlhTm+mGhMu0na46GPWX9b4r1uSINnnL\nRJuaiTa5PguteC0B1hIYLaGTERdI4WCAK6eWc/2MY/v8++MpIORwgcChQCnswfrOec92tIRHS2g0\nHPBOdbVvazgADTWHQql6GzTWecs21kJTQze+3OJCo32I5LQNknCW9wn5w3C2d3G/ZV5re7t5QfVz\nlQptQ2pg/AZNzXGhEfNCo02IxFzreGOsJViaaWxy/vJx063baKbBX/fQfH/bsUPT4X64rqOAkL5n\n5v+LPxvyEr5avHuaYhCt9UOj1h+vbRsi0ZbxDpZpOOA9hNi6fL23Tmen0joSCLULj/gQyYJQpG0A\ntcwLReJCKRL3yTzyUEdFA1IwYAQD3im/o5ECQga+YAiC+d71jr7knNdhYrTOO+KJ/8RaxusOhUmb\n9vhPHcTqvfGD+xIv39TYu1qDXQiR7g7DWf52M+KG/ngw7C0T9NtCmV4wKqjSigJC0peZ/xdmpnf3\nVjI1N7UNlKZGL1RiDf4wfrzBD5eGw9s7GtZXQWx3gvl9EE6t7FBYBMNdC5VuLxc33rpcpvePhEDY\nXyfkDQNhf9nwofFu9IosR6aAEOkPgaB/V1du/393c7N3HSdRuETrvQBpaoCmqNfe1OgHWPx446Hl\n4scTrRNr8K4ndbZcn4VWOxZIEBwZhwdMR+OtwdNJCCUc72i74UPbC4TaBlkg7LXFTwfDA+pITQEh\ncrQLBCDgX/sYKJzzQqPDwGkfKlFojvrrtIw3eten4sebGv3pjsajbbcVa4Tm2sTbSjTeXywYFx6h\nw8cDITjtBvjEN5JahgJCRPqfmXfaKZQBmakupouc804VdiV44kOsucmf9oOm/XRTLG5erO10wnn+\neG4f3AByBAoIEZGuMPNPPaXPX5vqiEdERBJSQIiISEIKCBERSUgBISIiCQ24gDCzmWb2vpltMLMF\nqa5HRCRdDaiAMLMgcB9wCTAJuM7MJqW2KhGR9DSgAgKYDmxwzm10zjUCjwGzUlyTiEhaGmgBMRLY\nEje91W9rZWbzzGypmS2tqKjo1+JERNLJoHviwzn3APAAgJlVmNnmHm6qGNjTZ4WllvZlYNK+DEza\nF+jSm4YGWkBsA0bFTZf7bQk550p6+kVmtrQrL+0eDLQvA5P2ZWDSvnTdQDvF9A4w3szGmFkGcC3w\nXIprEhFJSwPqCMI5FzOzrwMvAUHgIefcmhSXJSKSlgZUQAA4514AXuiHr3qgH76jv2hfBibty8Ck\nfekic64H7+QVEZGj3kC7BiEiIgOEAkJERBJKy4AY7P09mdkmM3vXzFaY2VK/baiZvWxm6/1hYarr\nTMTMHjKz3Wa2Oq4tYe3mudf/nVaZ2dTUVX64Dvblh2a2zf9tVpjZpXHzvufvy/tm9unUVH04Mxtl\nZovNbK2ZrTGzW/32Qfe7dLIvg/F3iZjZ22a20t+X2/32MWb2ll/z4/4dn5hZpj+9wZ8/utdFOOfS\n6oN3d9SHwFggA1gJTEp1Xd3ch01Acbu2nwAL/PEFwH+mus4Oaj8XmAqsPlLtwKXAi4ABM4C3Ul1/\nF/blh8C3Eyw7yf9vLRMY4/83GEz1Pvi1DQem+uN5wAd+vYPud+lkXwbj72JArj8eBt7y/7yfAK71\n2+8HbvbH/xW43x+/Fni8tzWk4xHE0drf0yzgYX/8YeDyFNbSIefcEmBvu+aOap8FPOI8bwIFZja8\nfyo9sg72pSOzgMeccw3OuY+ADXj/Laacc26Hc265P34AWIfXxc2g+1062ZeODOTfxTnnavzJsP9x\nwAXAU357+9+l5fd6CrjQzKw3NaRjQByxv6dBwAF/MbNlZjbPbyt1zu3wx3cCyX+jed/pqPbB+lt9\n3T/18lDcqb5BsS/+aYkpeP9aHdS/S7t9gUH4u5hZ0MxWALuBl/GOcPY752L+IvH1tu6LP78KKOrN\n96djQBwNznbOTcXrFn2+mZ0bP9N5x5iD8v7lwVy7byEwDpgM7AD+K7XldJ2Z5QJPA7c556rj5w22\n3yXBvgzK38U51+Scm4zX7dB0YEJ/fn86BkS3+nsaiJxz2/zhbuBZvP9wdrUc5vvD3amrsNs6qn3Q\n/VbOuV3+/9TNwIMcOl0xoPfFzMJ4f6H+1jn3jN88KH+XRPsyWH+XFs65/cBi4Ey8U3otDznH19u6\nL/78fKCyN9+bjgExqPt7MrMcM8trGQcuBlbj7cMN/mI3AH9MTYU90lHtzwFf8u+amQFUxZ3yGJDa\nnYu/Au+3AW9frvXvNBkDjAfe7u/6EvHPU/8KWOecuydu1qD7XTral0H6u5SYWYE/ngV8Cu+aymJg\ntr9Y+9+l5feaDfzVP/LruVRfqU/FB+8ujA/wzuf9e6rr6WbtY/HuulgJrGmpH+9c4yJgPfAKMDTV\ntXZQ/+/xDvGjeOdPb+yodry7OO7zf6d3gWmprr8L+/KoX+sq/3/Y4XHL/7u/L+8Dl6S6/ri6zsY7\nfbQKWOF/Lh2Mv0sn+zIYf5dTgH/6Na8Gvu+3j8ULsQ3Ak0Cm3x7xpzf488f2tgZ1tSEiIgml4ykm\nERHpAgWEiIgkpIAQEZGEFBAiIpKQAkJERBJSQIgAZlbjD0eb2b/08bb/rd30P/py+yLJooAQaWs0\n0K2AiHuqtSNtAsI594lu1iSSEgoIkbbuAs7x3xnwTb+ztJ+a2Tt+R29fBTCz883sNTN7Dljrt/3B\n70BxTUsnimZ2F5Dlb++3flvL0Yr5215t3vs9ronb9qtm9pSZvWdmv+1tr5wiPXGkf/mIpJsFeO8N\nuAzA/4u+yjl3upllAn83s7/4y04FTnJeN9EAX3bO7fW7RXjHzJ52zi0ws687r8O19q7E6zzuVKDY\nX2eJP28KcCKwHfg7cBbwet/vrkjHdAQh0rmL8fodWoHXbXQRXn89AG/HhQPALWa2EngTr9O08XTu\nbOD3zutEbhfwN+D0uG1vdV7ncivwTn2J9CsdQYh0zoBvOOdeatNodj5Q2276IuBM51ydmb2K1zdO\nTzXEjTeh/1clBXQEIdLWAbxXVbZ4CbjZ70IaMzve70W3vXxgnx8OE/BeDdki2rJ+O68B1/jXOUrw\nXmE6IHoSFQH9q0SkvVVAk3+q6DfAL/BO7yz3LxRXkPh1rn8GvmZm6/B6BX0zbt4DwCozW+6c+0Jc\n+7N4/fuvxOuB9LvOuZ1+wIiknHpzFRGRhHSKSUREElJAiIhIQgoIERFJSAEhIiIJKSBERCQhBYSI\niCSkgBARkYT+fw2qKsFqGfu3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6fc744df90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !python3\n",
    "# -*- coding:utf-8 -*-\n",
    "from numpy import *\n",
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_ITERATIONS = 300\n",
    "\n",
    "\n",
    "def  get_data(filename):\n",
    "    data = sklearn.datasets.load_svmlight_file(filename)\n",
    "    return data[0], data[1]\n",
    "\n",
    "\n",
    "def compute_loss(X, y, theta):\n",
    "    m = shape(X)[0]\n",
    "    dev = y - dot(X, theta)\n",
    "    loss = sum(dot(dev.T, dev)) / (2*m)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def optimizer_GD(X_train, y_train, X_validation, y_validation, initial_theta, learning_rate, num_iterations):\n",
    "    m = shape(X_train)[0]\n",
    "    theta = initial_theta\n",
    "    Ltrain = []\n",
    "    Lvalidation = []\n",
    "    for i in xrange(num_iterations):\n",
    "        Ltrain.append(compute_loss(X_train, y_train, theta))\n",
    "        Lvalidation.append(compute_loss(X_validation, y_validation, theta))\n",
    "        print('Loss of the ', i, ' iteration for train:', Ltrain[i])\n",
    "        print('Loss of the ', i, ' iteration for validation:', Lvalidation[i])\n",
    "        G = dot(X_train.transpose(), (dot(X_train, theta)-y_train)) / m\n",
    "        theta = theta - learning_rate * G\n",
    "\n",
    "    return Ltrain, Lvalidation\n",
    "\n",
    "\n",
    "def main():\n",
    "    # load data\n",
    "    X, y = get_data('./data/housing_scale')\n",
    "    X = X.todense()\n",
    "    y = y.reshape(len(y), 1)\n",
    "\n",
    "    # devide dataset\n",
    "    X_train, X_validation, y_train, y_validation = sklearn.model_selection.train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "    # initialize parameters\n",
    "    n = shape(X_train)[1]  # number of features\n",
    "    m_train = shape(X_train)[0]  # number of training examples\n",
    "    m_validation = shape(X_validation)[0]  # number of training examples\n",
    "    lr = LEARNING_RATE\n",
    "    num_iter = NUM_ITERATIONS\n",
    "    X_train = append(ones(shape=(m_train, 1)), X_train, 1)\n",
    "    X_validation = append(ones(shape=(m_validation, 1)), X_validation, 1)\n",
    "    initial_theta = zeros(shape=(n+1, 1))\n",
    "\n",
    "    # Linear Regression and Gradient Descent\n",
    "    Ltrain, Lvalidation = optimizer_GD(X_train, y_train, X_validation, y_validation, initial_theta, lr, num_iter)\n",
    "\n",
    "    # visualization\n",
    "    num_iter=xrange(num_iter)\n",
    "    plt.plot(num_iter, Ltrain, label='training_loss')\n",
    "    plt.plot(num_iter,Lvalidation,label='validation_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
