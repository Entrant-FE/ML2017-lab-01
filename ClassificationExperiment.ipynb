{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss of the ', 0, ' iteration for train:', 1.0)\n",
      "('Loss of the ', 0, ' iteration for validation:', 1.0)\n",
      "('Loss of the ', 1, ' iteration for train:', 0.90368073415983219)\n",
      "('Loss of the ', 1, ' iteration for validation:', 0.89680571349415805)\n",
      "('Loss of the ', 2, ' iteration for train:', 0.80740309083796746)\n",
      "('Loss of the ', 2, ' iteration for validation:', 0.79368333259292445)\n",
      "('Loss of the ', 3, ' iteration for train:', 0.71116705239083144)\n",
      "('Loss of the ', 3, ' iteration for validation:', 0.6906328213481675)\n",
      "('Loss of the ', 4, ' iteration for train:', 0.61502122940876869)\n",
      "('Loss of the ', 4, ' iteration for validation:', 0.58784009852090724)\n",
      "('Loss of the ', 5, ' iteration for train:', 0.54050771304980427)\n",
      "('Loss of the ', 5, ' iteration for validation:', 0.51045007082949523)\n",
      "('Loss of the ', 6, ' iteration for train:', 0.49656763384978392)\n",
      "('Loss of the ', 6, ' iteration for validation:', 0.47672199752195932)\n",
      "('Loss of the ', 7, ' iteration for train:', 0.45337043880194244)\n",
      "('Loss of the ', 7, ' iteration for validation:', 0.44264511150225605)\n",
      "('Loss of the ', 8, ' iteration for train:', 0.41264332368389689)\n",
      "('Loss of the ', 8, ' iteration for validation:', 0.41019088688640803)\n",
      "('Loss of the ', 9, ' iteration for train:', 0.38500460882672222)\n",
      "('Loss of the ', 9, ' iteration for validation:', 0.38972039447991152)\n",
      "('Loss of the ', 10, ' iteration for train:', 0.37361679589620961)\n",
      "('Loss of the ', 10, ' iteration for validation:', 0.38026655450356583)\n",
      "('Loss of the ', 11, ' iteration for train:', 0.3682965396643032)\n",
      "('Loss of the ', 11, ' iteration for validation:', 0.37522921072718801)\n",
      "('Loss of the ', 12, ' iteration for train:', 0.36418360950655754)\n",
      "('Loss of the ', 12, ' iteration for validation:', 0.37055051223834523)\n",
      "('Loss of the ', 13, ' iteration for train:', 0.36046524499056043)\n",
      "('Loss of the ', 13, ' iteration for validation:', 0.36681218218923195)\n",
      "('Loss of the ', 14, ' iteration for train:', 0.35677205621825164)\n",
      "('Loss of the ', 14, ' iteration for validation:', 0.36295757034870152)\n",
      "('Loss of the ', 15, ' iteration for train:', 0.3531721681941255)\n",
      "('Loss of the ', 15, ' iteration for validation:', 0.35927710040841526)\n",
      "('Loss of the ', 16, ' iteration for train:', 0.34959720210454692)\n",
      "('Loss of the ', 16, ' iteration for validation:', 0.35568636527465486)\n",
      "('Loss of the ', 17, ' iteration for train:', 0.34607407562847536)\n",
      "('Loss of the ', 17, ' iteration for validation:', 0.35215856089865866)\n",
      "('Loss of the ', 18, ' iteration for train:', 0.3425608644733753)\n",
      "('Loss of the ', 18, ' iteration for validation:', 0.34854139799740391)\n",
      "('Loss of the ', 19, ' iteration for train:', 0.33907762132554214)\n",
      "('Loss of the ', 19, ' iteration for validation:', 0.34501985720653194)\n",
      "('Loss of the ', 20, ' iteration for train:', 0.33560394809480465)\n",
      "('Loss of the ', 20, ' iteration for validation:', 0.34150089437713887)\n",
      "('Loss of the ', 21, ' iteration for train:', 0.33214997343704866)\n",
      "('Loss of the ', 21, ' iteration for validation:', 0.33809359954898033)\n",
      "('Loss of the ', 22, ' iteration for train:', 0.32872731174847314)\n",
      "('Loss of the ', 22, ' iteration for validation:', 0.3346437170154023)\n",
      "('Loss of the ', 23, ' iteration for train:', 0.32543068180875601)\n",
      "('Loss of the ', 23, ' iteration for validation:', 0.33151394122701716)\n",
      "('Loss of the ', 24, ' iteration for train:', 0.32235038031449376)\n",
      "('Loss of the ', 24, ' iteration for validation:', 0.32874847160976034)\n",
      "('Loss of the ', 25, ' iteration for train:', 0.31961824530477639)\n",
      "('Loss of the ', 25, ' iteration for validation:', 0.32634651187029429)\n",
      "('Loss of the ', 26, ' iteration for train:', 0.31702269184317766)\n",
      "('Loss of the ', 26, ' iteration for validation:', 0.32400693335776315)\n",
      "('Loss of the ', 27, ' iteration for train:', 0.31457888908840531)\n",
      "('Loss of the ', 27, ' iteration for validation:', 0.32184182133964695)\n",
      "('Loss of the ', 28, ' iteration for train:', 0.31217906608883567)\n",
      "('Loss of the ', 28, ' iteration for validation:', 0.31973355036782863)\n",
      "('Loss of the ', 29, ' iteration for train:', 0.30998983333081676)\n",
      "('Loss of the ', 29, ' iteration for validation:', 0.31784573430872864)\n",
      "('Loss of the ', 30, ' iteration for train:', 0.30805096169212742)\n",
      "('Loss of the ', 30, ' iteration for validation:', 0.31593003455473001)\n",
      "('Loss of the ', 31, ' iteration for train:', 0.30626446560083598)\n",
      "('Loss of the ', 31, ' iteration for validation:', 0.31434107371182546)\n",
      "('Loss of the ', 32, ' iteration for train:', 0.30465736211939076)\n",
      "('Loss of the ', 32, ' iteration for validation:', 0.31293404617610837)\n",
      "('Loss of the ', 33, ' iteration for train:', 0.30335800101055482)\n",
      "('Loss of the ', 33, ' iteration for validation:', 0.31161989397116918)\n",
      "('Loss of the ', 34, ' iteration for train:', 0.30228861476611507)\n",
      "('Loss of the ', 34, ' iteration for validation:', 0.31064052319084812)\n",
      "('Loss of the ', 35, ' iteration for train:', 0.30135109260913284)\n",
      "('Loss of the ', 35, ' iteration for validation:', 0.30965708580890106)\n",
      "('Loss of the ', 36, ' iteration for train:', 0.30048921366444326)\n",
      "('Loss of the ', 36, ' iteration for validation:', 0.30882785395319745)\n",
      "('Loss of the ', 37, ' iteration for train:', 0.299723946195389)\n",
      "('Loss of the ', 37, ' iteration for validation:', 0.30822797582092815)\n",
      "('Loss of the ', 38, ' iteration for train:', 0.29903884276597814)\n",
      "('Loss of the ', 38, ' iteration for validation:', 0.30757294107867894)\n",
      "('Loss of the ', 39, ' iteration for train:', 0.29844621577663449)\n",
      "('Loss of the ', 39, ' iteration for validation:', 0.30700945674120594)\n",
      "('Loss of the ', 40, ' iteration for train:', 0.29795751523042302)\n",
      "('Loss of the ', 40, ' iteration for validation:', 0.30653315694881961)\n",
      "('Loss of the ', 41, ' iteration for train:', 0.2974843645259429)\n",
      "('Loss of the ', 41, ' iteration for validation:', 0.30588085556646621)\n",
      "('Loss of the ', 42, ' iteration for train:', 0.29711390139363597)\n",
      "('Loss of the ', 42, ' iteration for validation:', 0.30553497341463065)\n",
      "('Loss of the ', 43, ' iteration for train:', 0.29679698304351276)\n",
      "('Loss of the ', 43, ' iteration for validation:', 0.30523211615199936)\n",
      "('Loss of the ', 44, ' iteration for train:', 0.29656157335598154)\n",
      "('Loss of the ', 44, ' iteration for validation:', 0.30506182598460063)\n",
      "('Loss of the ', 45, ' iteration for train:', 0.29637358026400151)\n",
      "('Loss of the ', 45, ' iteration for validation:', 0.30458890880349176)\n",
      "('Loss of the ', 46, ' iteration for train:', 0.29612029940418733)\n",
      "('Loss of the ', 46, ' iteration for validation:', 0.30453639673448063)\n",
      "('Loss of the ', 47, ' iteration for train:', 0.29591481777702128)\n",
      "('Loss of the ', 47, ' iteration for validation:', 0.30435926998243285)\n",
      "('Loss of the ', 48, ' iteration for train:', 0.29574351002901639)\n",
      "('Loss of the ', 48, ' iteration for validation:', 0.30419414527781174)\n",
      "('Loss of the ', 49, ' iteration for train:', 0.29559010472381175)\n",
      "('Loss of the ', 49, ' iteration for validation:', 0.30404287293096049)\n",
      "('Loss of the ', 50, ' iteration for train:', 0.29545036457986668)\n",
      "('Loss of the ', 50, ' iteration for validation:', 0.30386390730185814)\n",
      "('Loss of the ', 51, ' iteration for train:', 0.29532721152206515)\n",
      "('Loss of the ', 51, ' iteration for validation:', 0.30392229103345314)\n",
      "('Loss of the ', 52, ' iteration for train:', 0.29519468172772118)\n",
      "('Loss of the ', 52, ' iteration for validation:', 0.30350067116959889)\n",
      "('Loss of the ', 53, ' iteration for train:', 0.29505244875716491)\n",
      "('Loss of the ', 53, ' iteration for validation:', 0.30361004555036203)\n",
      "('Loss of the ', 54, ' iteration for train:', 0.29493754632347574)\n",
      "('Loss of the ', 54, ' iteration for validation:', 0.30324907342573443)\n",
      "('Loss of the ', 55, ' iteration for train:', 0.29480126671802698)\n",
      "('Loss of the ', 55, ' iteration for validation:', 0.30336140831188257)\n",
      "('Loss of the ', 56, ' iteration for train:', 0.29467942211414971)\n",
      "('Loss of the ', 56, ' iteration for validation:', 0.30325759915382489)\n",
      "('Loss of the ', 57, ' iteration for train:', 0.29456439108784394)\n",
      "('Loss of the ', 57, ' iteration for validation:', 0.30311292577510807)\n",
      "('Loss of the ', 58, ' iteration for train:', 0.29447086230903413)\n",
      "('Loss of the ', 58, ' iteration for validation:', 0.30291949591362727)\n",
      "('Loss of the ', 59, ' iteration for train:', 0.29437225346202184)\n",
      "('Loss of the ', 59, ' iteration for validation:', 0.30289340282714572)\n",
      "('Loss of the ', 60, ' iteration for train:', 0.2942795227961828)\n",
      "('Loss of the ', 60, ' iteration for validation:', 0.30275421414973719)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss of the ', 61, ' iteration for train:', 0.29420049830602851)\n",
      "('Loss of the ', 61, ' iteration for validation:', 0.30265068775168452)\n",
      "('Loss of the ', 62, ' iteration for train:', 0.29412431201037387)\n",
      "('Loss of the ', 62, ' iteration for validation:', 0.30259618219842133)\n",
      "('Loss of the ', 63, ' iteration for train:', 0.29404514980217666)\n",
      "('Loss of the ', 63, ' iteration for validation:', 0.30244175649278032)\n",
      "('Loss of the ', 64, ' iteration for train:', 0.29396949430808089)\n",
      "('Loss of the ', 64, ' iteration for validation:', 0.30238613722962704)\n",
      "('Loss of the ', 65, ' iteration for train:', 0.29389180961271788)\n",
      "('Loss of the ', 65, ' iteration for validation:', 0.30224049657854335)\n",
      "('Loss of the ', 66, ' iteration for train:', 0.29382192279263192)\n",
      "('Loss of the ', 66, ' iteration for validation:', 0.30228081354191938)\n",
      "('Loss of the ', 67, ' iteration for train:', 0.29376367732041292)\n",
      "('Loss of the ', 67, ' iteration for validation:', 0.30202381691449343)\n",
      "('Loss of the ', 68, ' iteration for train:', 0.29368800236247294)\n",
      "('Loss of the ', 68, ' iteration for validation:', 0.30222923836495946)\n",
      "('Loss of the ', 69, ' iteration for train:', 0.29362248420034354)\n",
      "('Loss of the ', 69, ' iteration for validation:', 0.30184549200243938)\n",
      "('Loss of the ', 70, ' iteration for train:', 0.29355051955121958)\n",
      "('Loss of the ', 70, ' iteration for validation:', 0.30213385441283808)\n",
      "('Loss of the ', 71, ' iteration for train:', 0.2934802198663447)\n",
      "('Loss of the ', 71, ' iteration for validation:', 0.30175162267216321)\n",
      "('Loss of the ', 72, ' iteration for train:', 0.29340088661386005)\n",
      "('Loss of the ', 72, ' iteration for validation:', 0.30196891772065532)\n",
      "('Loss of the ', 73, ' iteration for train:', 0.29332524578908348)\n",
      "('Loss of the ', 73, ' iteration for validation:', 0.30169239793491465)\n",
      "('Loss of the ', 74, ' iteration for train:', 0.2932619028805416)\n",
      "('Loss of the ', 74, ' iteration for validation:', 0.30186914283850291)\n",
      "('Loss of the ', 75, ' iteration for train:', 0.29321142473605982)\n",
      "('Loss of the ', 75, ' iteration for validation:', 0.30148734197317278)\n",
      "('Loss of the ', 76, ' iteration for train:', 0.29311306772475348)\n",
      "('Loss of the ', 76, ' iteration for validation:', 0.30171393564765459)\n",
      "('Loss of the ', 77, ' iteration for train:', 0.29305660734632694)\n",
      "('Loss of the ', 77, ' iteration for validation:', 0.30144713195909612)\n",
      "('Loss of the ', 78, ' iteration for train:', 0.29298187943029014)\n",
      "('Loss of the ', 78, ' iteration for validation:', 0.30166251852161341)\n",
      "('Loss of the ', 79, ' iteration for train:', 0.29294703954897366)\n",
      "('Loss of the ', 79, ' iteration for validation:', 0.30124943474204469)\n",
      "('Loss of the ', 80, ' iteration for train:', 0.2928729911599765)\n",
      "('Loss of the ', 80, ' iteration for validation:', 0.30168974741979232)\n",
      "('Loss of the ', 81, ' iteration for train:', 0.29284379876776584)\n",
      "('Loss of the ', 81, ' iteration for validation:', 0.30114960755318659)\n",
      "('Loss of the ', 82, ' iteration for train:', 0.29278844507646867)\n",
      "('Loss of the ', 82, ' iteration for validation:', 0.30177824002066117)\n",
      "('Loss of the ', 83, ' iteration for train:', 0.29281029533923858)\n",
      "('Loss of the ', 83, ' iteration for validation:', 0.30100557286353874)\n",
      "('Loss of the ', 84, ' iteration for train:', 0.29278504232257507)\n",
      "('Loss of the ', 84, ' iteration for validation:', 0.30200112955358055)\n",
      "('Loss of the ', 85, ' iteration for train:', 0.29278111000106732)\n",
      "('Loss of the ', 85, ' iteration for validation:', 0.30089399442033277)\n",
      "('Loss of the ', 86, ' iteration for train:', 0.29261525753236522)\n",
      "('Loss of the ', 86, ' iteration for validation:', 0.30187614951159847)\n",
      "('Loss of the ', 87, ' iteration for train:', 0.29271229039110047)\n",
      "('Loss of the ', 87, ' iteration for validation:', 0.30082881690116198)\n",
      "('Loss of the ', 88, ' iteration for train:', 0.29249770471713848)\n",
      "('Loss of the ', 88, ' iteration for validation:', 0.30185547858887946)\n",
      "('Loss of the ', 89, ' iteration for train:', 0.29259251639338052)\n",
      "('Loss of the ', 89, ' iteration for validation:', 0.30081291472318816)\n",
      "('Loss of the ', 90, ' iteration for train:', 0.29238177651692493)\n",
      "('Loss of the ', 90, ' iteration for validation:', 0.30184366444330779)\n",
      "('Loss of the ', 91, ' iteration for train:', 0.29239940663313835)\n",
      "('Loss of the ', 91, ' iteration for validation:', 0.30080237713682878)\n",
      "('Loss of the ', 92, ' iteration for train:', 0.29221010194892194)\n",
      "('Loss of the ', 92, ' iteration for validation:', 0.30165423962340654)\n",
      "('Loss of the ', 93, ' iteration for train:', 0.29215670910970953)\n",
      "('Loss of the ', 93, ' iteration for validation:', 0.30088555800497419)\n",
      "('Loss of the ', 94, ' iteration for train:', 0.29209526964226751)\n",
      "('Loss of the ', 94, ' iteration for validation:', 0.3015872820831238)\n",
      "('Loss of the ', 95, ' iteration for train:', 0.29204754336067507)\n",
      "('Loss of the ', 95, ' iteration for validation:', 0.30083383197504382)\n",
      "('Loss of the ', 96, ' iteration for train:', 0.2919517824319165)\n",
      "('Loss of the ', 96, ' iteration for validation:', 0.30143721993262351)\n",
      "('Loss of the ', 97, ' iteration for train:', 0.29196944438766886)\n",
      "('Loss of the ', 97, ' iteration for validation:', 0.30073267901508027)\n",
      "('Loss of the ', 98, ' iteration for train:', 0.29191428264024832)\n",
      "('Loss of the ', 98, ' iteration for validation:', 0.30158517468159013)\n",
      "('Loss of the ', 99, ' iteration for train:', 0.29199716351789101)\n",
      "('Loss of the ', 99, ' iteration for validation:', 0.30058718594632156)\n",
      "('Loss of the ', 100, ' iteration for train:', 0.29182638111270753)\n",
      "('Loss of the ', 100, ' iteration for validation:', 0.30161863724657834)\n",
      "('Loss of the ', 101, ' iteration for train:', 0.29185095328599164)\n",
      "('Loss of the ', 101, ' iteration for validation:', 0.30055014993252926)\n",
      "('Loss of the ', 102, ' iteration for train:', 0.29167047609570823)\n",
      "('Loss of the ', 102, ' iteration for validation:', 0.30146732989912073)\n",
      "('Loss of the ', 103, ' iteration for train:', 0.2917137311302283)\n",
      "('Loss of the ', 103, ' iteration for validation:', 0.30055985476429303)\n",
      "('Loss of the ', 104, ' iteration for train:', 0.29152326722183702)\n",
      "('Loss of the ', 104, ' iteration for validation:', 0.30132421381040386)\n",
      "('Loss of the ', 105, ' iteration for train:', 0.29152270390312879)\n",
      "('Loss of the ', 105, ' iteration for validation:', 0.30060882939879063)\n",
      "('Loss of the ', 106, ' iteration for train:', 0.29148473354773563)\n",
      "('Loss of the ', 106, ' iteration for validation:', 0.30137048663003102)\n",
      "('Loss of the ', 107, ' iteration for train:', 0.29160401219425663)\n",
      "('Loss of the ', 107, ' iteration for validation:', 0.30036716287022663)\n",
      "('Loss of the ', 108, ' iteration for train:', 0.29160988350401201)\n",
      "('Loss of the ', 108, ' iteration for validation:', 0.30169923117456032)\n",
      "('Loss of the ', 109, ' iteration for train:', 0.29194448198843714)\n",
      "('Loss of the ', 109, ' iteration for validation:', 0.30023502164965193)\n",
      "('Loss of the ', 110, ' iteration for train:', 0.29170452873115121)\n",
      "('Loss of the ', 110, ' iteration for validation:', 0.30185655512738213)\n",
      "('Loss of the ', 111, ' iteration for train:', 0.292109417117837)\n",
      "('Loss of the ', 111, ' iteration for validation:', 0.30020001441942168)\n",
      "('Loss of the ', 112, ' iteration for train:', 0.29164244649090137)\n",
      "('Loss of the ', 112, ' iteration for validation:', 0.30182378143816629)\n",
      "('Loss of the ', 113, ' iteration for train:', 0.29201738180606557)\n",
      "('Loss of the ', 113, ' iteration for validation:', 0.30020712867186816)\n",
      "('Loss of the ', 114, ' iteration for train:', 0.29158692714059159)\n",
      "('Loss of the ', 114, ' iteration for validation:', 0.30180179825294962)\n",
      "('Loss of the ', 115, ' iteration for train:', 0.29179339117272074)\n",
      "('Loss of the ', 115, ' iteration for validation:', 0.3001615321320425)\n",
      "('Loss of the ', 116, ' iteration for train:', 0.29160144440316188)\n",
      "('Loss of the ', 116, ' iteration for validation:', 0.30184747929927502)\n",
      "('Loss of the ', 117, ' iteration for train:', 0.29223719118483565)\n",
      "('Loss of the ', 117, ' iteration for validation:', 0.30025124583422608)\n",
      "('Loss of the ', 118, ' iteration for train:', 0.29175705019942694)\n",
      "('Loss of the ', 118, ' iteration for validation:', 0.30202513561266819)\n",
      "('Loss of the ', 119, ' iteration for train:', 0.29218196918649453)\n",
      "('Loss of the ', 119, ' iteration for validation:', 0.3002721937234531)\n",
      "('Loss of the ', 120, ' iteration for train:', 0.29169748051360034)\n",
      "('Loss of the ', 120, ' iteration for validation:', 0.30200233730515075)\n",
      "('Loss of the ', 121, ' iteration for train:', 0.29222835954617321)\n",
      "('Loss of the ', 121, ' iteration for validation:', 0.30034358003366635)\n",
      "('Loss of the ', 122, ' iteration for train:', 0.29154281443969726)\n",
      "('Loss of the ', 122, ' iteration for validation:', 0.30189711374870409)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss of the ', 123, ' iteration for train:', 0.29207810103204068)\n",
      "('Loss of the ', 123, ' iteration for validation:', 0.30033003326114732)\n",
      "('Loss of the ', 124, ' iteration for train:', 0.29158435456888965)\n",
      "('Loss of the ', 124, ' iteration for validation:', 0.30197126802139451)\n",
      "('Loss of the ', 125, ' iteration for train:', 0.29214424061522692)\n",
      "('Loss of the ', 125, ' iteration for validation:', 0.30043072888814132)\n",
      "('Loss of the ', 126, ' iteration for train:', 0.29142786386011177)\n",
      "('Loss of the ', 126, ' iteration for validation:', 0.3018709258013661)\n",
      "('Loss of the ', 127, ' iteration for train:', 0.29174534908972583)\n",
      "('Loss of the ', 127, ' iteration for validation:', 0.30033815943336001)\n",
      "('Loss of the ', 128, ' iteration for train:', 0.29150586007264523)\n",
      "('Loss of the ', 128, ' iteration for validation:', 0.3019807166061329)\n",
      "('Loss of the ', 129, ' iteration for train:', 0.29190613577464425)\n",
      "('Loss of the ', 129, ' iteration for validation:', 0.30043099153008929)\n",
      "('Loss of the ', 130, ' iteration for train:', 0.29156720657465618)\n",
      "('Loss of the ', 130, ' iteration for validation:', 0.30210862880369432)\n",
      "('Loss of the ', 131, ' iteration for train:', 0.29192620635516303)\n",
      "('Loss of the ', 131, ' iteration for validation:', 0.30049186846993037)\n",
      "('Loss of the ', 132, ' iteration for train:', 0.29155045806901864)\n",
      "('Loss of the ', 132, ' iteration for validation:', 0.30213432582212862)\n",
      "('Loss of the ', 133, ' iteration for train:', 0.29156886522348185)\n",
      "('Loss of the ', 133, ' iteration for validation:', 0.30042639395841486)\n",
      "('Loss of the ', 134, ' iteration for train:', 0.29132305323989538)\n",
      "('Loss of the ', 134, ' iteration for validation:', 0.30193028921507964)\n",
      "('Loss of the ', 135, ' iteration for train:', 0.29149451329791115)\n",
      "('Loss of the ', 135, ' iteration for validation:', 0.30040544163388372)\n",
      "('Loss of the ', 136, ' iteration for train:', 0.29162668279635873)\n",
      "('Loss of the ', 136, ' iteration for validation:', 0.30222084782052333)\n",
      "('Loss of the ', 137, ' iteration for train:', 0.29208567441982158)\n",
      "('Loss of the ', 137, ' iteration for validation:', 0.3006741872889731)\n",
      "('Loss of the ', 138, ' iteration for train:', 0.29176785026360125)\n",
      "('Loss of the ', 138, ' iteration for validation:', 0.30244134241008519)\n",
      "('Loss of the ', 139, ' iteration for train:', 0.292055057942049)\n",
      "('Loss of the ', 139, ' iteration for validation:', 0.30076777227125356)\n",
      "('Loss of the ', 140, ' iteration for train:', 0.29161575962495428)\n",
      "('Loss of the ', 140, ' iteration for validation:', 0.30237881624242069)\n",
      "('Loss of the ', 141, ' iteration for train:', 0.29154102747181393)\n",
      "('Loss of the ', 141, ' iteration for validation:', 0.30062477672664562)\n",
      "('Loss of the ', 142, ' iteration for train:', 0.29134677270402631)\n",
      "('Loss of the ', 142, ' iteration for validation:', 0.30215011059952562)\n",
      "('Loss of the ', 143, ' iteration for train:', 0.29145720482461956)\n",
      "('Loss of the ', 143, ' iteration for validation:', 0.30060692705485015)\n",
      "('Loss of the ', 144, ' iteration for train:', 0.29135933669610348)\n",
      "('Loss of the ', 144, ' iteration for validation:', 0.30219974593482291)\n",
      "('Loss of the ', 145, ' iteration for train:', 0.29159994482871293)\n",
      "('Loss of the ', 145, ' iteration for validation:', 0.30066286573491202)\n",
      "('Loss of the ', 146, ' iteration for train:', 0.29186952121192294)\n",
      "('Loss of the ', 146, ' iteration for validation:', 0.30271268334774709)\n",
      "('Loss of the ', 147, ' iteration for train:', 0.29275317322349637)\n",
      "('Loss of the ', 147, ' iteration for validation:', 0.30124421581923205)\n",
      "('Loss of the ', 148, ' iteration for train:', 0.29294723035393994)\n",
      "('Loss of the ', 148, ' iteration for validation:', 0.30390981906639242)\n",
      "('Loss of the ', 149, ' iteration for train:', 0.29364216759138556)\n",
      "('Loss of the ', 149, ' iteration for validation:', 0.3019187515579439)\n",
      "('Loss of the ', 150, ' iteration for train:', 0.29252182031943447)\n",
      "('Loss of the ', 150, ' iteration for validation:', 0.3037063090892767)\n",
      "('Loss of the ', 151, ' iteration for train:', 0.29159780592772389)\n",
      "('Loss of the ', 151, ' iteration for validation:', 0.30120502452389031)\n",
      "('Loss of the ', 152, ' iteration for train:', 0.29137262493146998)\n",
      "('Loss of the ', 152, ' iteration for validation:', 0.30258207365169992)\n",
      "('Loss of the ', 153, ' iteration for train:', 0.29107196489673093)\n",
      "('Loss of the ', 153, ' iteration for validation:', 0.30098844134589214)\n",
      "('Loss of the ', 154, ' iteration for train:', 0.29116955800117172)\n",
      "('Loss of the ', 154, ' iteration for validation:', 0.3024132181790295)\n",
      "('Loss of the ', 155, ' iteration for train:', 0.29110711858278082)\n",
      "('Loss of the ', 155, ' iteration for validation:', 0.30093165815611822)\n",
      "('Loss of the ', 156, ' iteration for train:', 0.2914688615851927)\n",
      "('Loss of the ', 156, ' iteration for validation:', 0.30272647252639395)\n",
      "('Loss of the ', 157, ' iteration for train:', 0.29181476150899754)\n",
      "('Loss of the ', 157, ' iteration for validation:', 0.30115220718263397)\n",
      "('Loss of the ', 158, ' iteration for train:', 0.29178815007611086)\n",
      "('Loss of the ', 158, ' iteration for validation:', 0.30311514413527801)\n",
      "('Loss of the ', 159, ' iteration for train:', 0.29178709623169707)\n",
      "('Loss of the ', 159, ' iteration for validation:', 0.30124959120771988)\n",
      "('Loss of the ', 160, ' iteration for train:', 0.29151768387197308)\n",
      "('Loss of the ', 160, ' iteration for validation:', 0.30293517472890619)\n",
      "('Loss of the ', 161, ' iteration for train:', 0.29133090573928322)\n",
      "('Loss of the ', 161, ' iteration for validation:', 0.30118847376048563)\n",
      "('Loss of the ', 162, ' iteration for train:', 0.29130885664127448)\n",
      "('Loss of the ', 162, ' iteration for validation:', 0.30279974951213368)\n",
      "('Loss of the ', 163, ' iteration for train:', 0.29139060421961616)\n",
      "('Loss of the ', 163, ' iteration for validation:', 0.30123439412137526)\n",
      "('Loss of the ', 164, ' iteration for train:', 0.29161103459795362)\n",
      "('Loss of the ', 164, ' iteration for validation:', 0.3031107683576395)\n",
      "('Loss of the ', 165, ' iteration for train:', 0.2918439508525888)\n",
      "('Loss of the ', 165, ' iteration for validation:', 0.30142742531560124)\n",
      "('Loss of the ', 166, ' iteration for train:', 0.2917134403209044)\n",
      "('Loss of the ', 166, ' iteration for validation:', 0.30333280463518159)\n",
      "('Loss of the ', 167, ' iteration for train:', 0.29182023332729701)\n",
      "('Loss of the ', 167, ' iteration for validation:', 0.30154269269083506)\n",
      "('Loss of the ', 168, ' iteration for train:', 0.29157466596356263)\n",
      "('Loss of the ', 168, ' iteration for validation:', 0.30329365410977627)\n",
      "('Loss of the ', 169, ' iteration for train:', 0.29133495388319397)\n",
      "('Loss of the ', 169, ' iteration for validation:', 0.30150275882791899)\n",
      "('Loss of the ', 170, ' iteration for train:', 0.29132823215618514)\n",
      "('Loss of the ', 170, ' iteration for validation:', 0.30310636397464769)\n",
      "('Loss of the ', 171, ' iteration for train:', 0.29121661040522906)\n",
      "('Loss of the ', 171, ' iteration for validation:', 0.30145386752632569)\n",
      "('Loss of the ', 172, ' iteration for train:', 0.29130806971713447)\n",
      "('Loss of the ', 172, ' iteration for validation:', 0.30311774680355397)\n",
      "('Loss of the ', 173, ' iteration for train:', 0.29118317664491528)\n",
      "('Loss of the ', 173, ' iteration for validation:', 0.30144926047347875)\n",
      "('Loss of the ', 174, ' iteration for train:', 0.29129501808673947)\n",
      "('Loss of the ', 174, ' iteration for validation:', 0.30312916083178942)\n",
      "('Loss of the ', 175, ' iteration for train:', 0.29160901114112531)\n",
      "('Loss of the ', 175, ' iteration for validation:', 0.30161268236690242)\n",
      "('Loss of the ', 176, ' iteration for train:', 0.29189562936470598)\n",
      "('Loss of the ', 176, ' iteration for validation:', 0.30379267711516306)\n",
      "('Loss of the ', 177, ' iteration for train:', 0.29206661984952259)\n",
      "('Loss of the ', 177, ' iteration for validation:', 0.30197646914927073)\n",
      "('Loss of the ', 178, ' iteration for train:', 0.29163925539413232)\n",
      "('Loss of the ', 178, ' iteration for validation:', 0.30372689733449998)\n",
      "('Loss of the ', 179, ' iteration for train:', 0.29100810021122564)\n",
      "('Loss of the ', 179, ' iteration for validation:', 0.30175998787679276)\n",
      "('Loss of the ', 180, ' iteration for train:', 0.29116406597810823)\n",
      "('Loss of the ', 180, ' iteration for validation:', 0.30328165623683917)\n",
      "('Loss of the ', 181, ' iteration for train:', 0.29077248540422751)\n",
      "('Loss of the ', 181, ' iteration for validation:', 0.30162680499053451)\n",
      "('Loss of the ', 182, ' iteration for train:', 0.2912498631282176)\n",
      "('Loss of the ', 182, ' iteration for validation:', 0.30341005676264515)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss of the ', 183, ' iteration for train:', 0.29163227199500508)\n",
      "('Loss of the ', 183, ' iteration for validation:', 0.30191357927895435)\n",
      "('Loss of the ', 184, ' iteration for train:', 0.29185771817277467)\n",
      "('Loss of the ', 184, ' iteration for validation:', 0.3040794802881398)\n",
      "('Loss of the ', 185, ' iteration for train:', 0.29199027940006544)\n",
      "('Loss of the ', 185, ' iteration for validation:', 0.30220454261922286)\n",
      "('Loss of the ', 186, ' iteration for train:', 0.29156436840070427)\n",
      "('Loss of the ', 186, ' iteration for validation:', 0.30394458941258418)\n",
      "('Loss of the ', 187, ' iteration for train:', 0.29115414428056652)\n",
      "('Loss of the ', 187, ' iteration for validation:', 0.30203691071445277)\n",
      "('Loss of the ', 188, ' iteration for train:', 0.29117515737869687)\n",
      "('Loss of the ', 188, ' iteration for validation:', 0.303584115274044)\n",
      "('Loss of the ', 189, ' iteration for train:', 0.29080571333383887)\n",
      "('Loss of the ', 189, ' iteration for validation:', 0.30192197815057303)\n",
      "('Loss of the ', 190, ' iteration for train:', 0.29115988607180476)\n",
      "('Loss of the ', 190, ' iteration for validation:', 0.30364420833135441)\n",
      "('Loss of the ', 191, ' iteration for train:', 0.29121248947291622)\n",
      "('Loss of the ', 191, ' iteration for validation:', 0.302059331294742)\n",
      "('Loss of the ', 192, ' iteration for train:', 0.2913374722303157)\n",
      "('Loss of the ', 192, ' iteration for validation:', 0.30385505807318336)\n",
      "('Loss of the ', 193, ' iteration for train:', 0.29157970904826769)\n",
      "('Loss of the ', 193, ' iteration for validation:', 0.30224933392456721)\n",
      "('Loss of the ', 194, ' iteration for train:', 0.29169975559500111)\n",
      "('Loss of the ', 194, ' iteration for validation:', 0.30431122540516675)\n",
      "('Loss of the ', 195, ' iteration for train:', 0.29168790880006623)\n",
      "('Loss of the ', 195, ' iteration for validation:', 0.30242899550654812)\n",
      "('Loss of the ', 196, ' iteration for train:', 0.29142184945510807)\n",
      "('Loss of the ', 196, ' iteration for validation:', 0.30415897755343002)\n",
      "('Loss of the ', 197, ' iteration for train:', 0.29110270816315864)\n",
      "('Loss of the ', 197, ' iteration for validation:', 0.30234157197624939)\n",
      "('Loss of the ', 198, ' iteration for train:', 0.29112173204749364)\n",
      "('Loss of the ', 198, ' iteration for validation:', 0.30389702110939087)\n",
      "('Loss of the ', 199, ' iteration for train:', 0.29077711664858169)\n",
      "('Loss of the ', 199, ' iteration for validation:', 0.30225671523084852)\n",
      "('Loss of the ', 200, ' iteration for train:', 0.29118292779504051)\n",
      "('Loss of the ', 200, ' iteration for validation:', 0.30398775909036646)\n",
      "('Loss of the ', 201, ' iteration for train:', 0.29120537361862553)\n",
      "('Loss of the ', 201, ' iteration for validation:', 0.30239197410979307)\n",
      "('Loss of the ', 202, ' iteration for train:', 0.29115197046033087)\n",
      "('Loss of the ', 202, ' iteration for validation:', 0.30404017224046448)\n",
      "('Loss of the ', 203, ' iteration for train:', 0.29132724505294033)\n",
      "('Loss of the ', 203, ' iteration for validation:', 0.30251346387789779)\n",
      "('Loss of the ', 204, ' iteration for train:', 0.29163489348381066)\n",
      "('Loss of the ', 204, ' iteration for validation:', 0.30460866352769023)\n",
      "('Loss of the ', 205, ' iteration for train:', 0.29184669673260066)\n",
      "('Loss of the ', 205, ' iteration for validation:', 0.30282399870536697)\n",
      "('Loss of the ', 206, ' iteration for train:', 0.29185737341845863)\n",
      "('Loss of the ', 206, ' iteration for validation:', 0.30492363295812658)\n",
      "('Loss of the ', 207, ' iteration for train:', 0.29146907767715285)\n",
      "('Loss of the ', 207, ' iteration for validation:', 0.30276721567390685)\n",
      "('Loss of the ', 208, ' iteration for train:', 0.29096024164805845)\n",
      "('Loss of the ', 208, ' iteration for validation:', 0.3040919189150722)\n",
      "('Loss of the ', 209, ' iteration for train:', 0.29059528390563644)\n",
      "('Loss of the ', 209, ' iteration for validation:', 0.30255030356924079)\n",
      "('Loss of the ', 210, ' iteration for train:', 0.29087010802482399)\n",
      "('Loss of the ', 210, ' iteration for validation:', 0.30408438973831575)\n",
      "('Loss of the ', 211, ' iteration for train:', 0.29091278500887063)\n",
      "('Loss of the ', 211, ' iteration for validation:', 0.30261615657145824)\n",
      "('Loss of the ', 212, ' iteration for train:', 0.29103217710301477)\n",
      "('Loss of the ', 212, ' iteration for validation:', 0.30426412981573553)\n",
      "('Loss of the ', 213, ' iteration for train:', 0.29115389502523192)\n",
      "('Loss of the ', 213, ' iteration for validation:', 0.30273068070757297)\n",
      "('Loss of the ', 214, ' iteration for train:', 0.29134862614453516)\n",
      "('Loss of the ', 214, ' iteration for validation:', 0.3046710446169239)\n",
      "('Loss of the ', 215, ' iteration for train:', 0.29142610542145908)\n",
      "('Loss of the ', 215, ' iteration for validation:', 0.30293151479705327)\n",
      "('Loss of the ', 216, ' iteration for train:', 0.29156794336453401)\n",
      "('Loss of the ', 216, ' iteration for validation:', 0.30499041610492744)\n",
      "('Loss of the ', 217, ' iteration for train:', 0.29128893107585124)\n",
      "('Loss of the ', 217, ' iteration for validation:', 0.30302714028904637)\n",
      "('Loss of the ', 218, ' iteration for train:', 0.29104470072538341)\n",
      "('Loss of the ', 218, ' iteration for validation:', 0.3045602990395756)\n",
      "('Loss of the ', 219, ' iteration for train:', 0.29061620776581282)\n",
      "('Loss of the ', 219, ' iteration for validation:', 0.30287958129712284)\n",
      "('Loss of the ', 220, ' iteration for train:', 0.29098465839614179)\n",
      "('Loss of the ', 220, ' iteration for validation:', 0.3045323026782385)\n",
      "('Loss of the ', 221, ' iteration for train:', 0.29093284658627938)\n",
      "('Loss of the ', 221, ' iteration for validation:', 0.30295380101672609)\n",
      "('Loss of the ', 222, ' iteration for train:', 0.29093598391021175)\n",
      "('Loss of the ', 222, ' iteration for validation:', 0.30454585309966126)\n",
      "('Loss of the ', 223, ' iteration for train:', 0.290925576598556)\n",
      "('Loss of the ', 223, ' iteration for validation:', 0.30300706857222209)\n",
      "('Loss of the ', 224, ' iteration for train:', 0.29102150617878675)\n",
      "('Loss of the ', 224, ' iteration for validation:', 0.30469952185965948)\n",
      "('Loss of the ', 225, ' iteration for train:', 0.2910411653875532)\n",
      "('Loss of the ', 225, ' iteration for validation:', 0.3031333156451001)\n",
      "('Loss of the ', 226, ' iteration for train:', 0.29110907546656412)\n",
      "('Loss of the ', 226, ' iteration for validation:', 0.30489368232892916)\n",
      "('Loss of the ', 227, ' iteration for train:', 0.29118080159388005)\n",
      "('Loss of the ', 227, ' iteration for validation:', 0.30327081495993991)\n",
      "('Loss of the ', 228, ' iteration for train:', 0.29145713637045306)\n",
      "('Loss of the ', 228, ' iteration for validation:', 0.30533043228309725)\n",
      "('Loss of the ', 229, ' iteration for train:', 0.29132818898351193)\n",
      "('Loss of the ', 229, ' iteration for validation:', 0.30343733433270942)\n",
      "('Loss of the ', 230, ' iteration for train:', 0.29126351498881042)\n",
      "('Loss of the ', 230, ' iteration for validation:', 0.30525866302369092)\n",
      "('Loss of the ', 231, ' iteration for train:', 0.29075852672583513)\n",
      "('Loss of the ', 231, ' iteration for validation:', 0.30337984537532275)\n",
      "('Loss of the ', 232, ' iteration for train:', 0.29064691324958342)\n",
      "('Loss of the ', 232, ' iteration for validation:', 0.30468929238987202)\n",
      "('Loss of the ', 233, ' iteration for train:', 0.29044012222333304)\n",
      "('Loss of the ', 233, ' iteration for validation:', 0.30326389106084983)\n",
      "('Loss of the ', 234, ' iteration for train:', 0.29079404811242371)\n",
      "('Loss of the ', 234, ' iteration for validation:', 0.30484912327022418)\n",
      "('Loss of the ', 235, ' iteration for train:', 0.29074264357635193)\n",
      "('Loss of the ', 235, ' iteration for validation:', 0.30333795457585216)\n",
      "('Loss of the ', 236, ' iteration for train:', 0.29086555638438122)\n",
      "('Loss of the ', 236, ' iteration for validation:', 0.30497358036850225)\n",
      "('Loss of the ', 237, ' iteration for train:', 0.29085325053019123)\n",
      "('Loss of the ', 237, ' iteration for validation:', 0.3034473766687944)\n",
      "('Loss of the ', 238, ' iteration for train:', 0.29118890844965656)\n",
      "('Loss of the ', 238, ' iteration for validation:', 0.30539458131246661)\n",
      "('Loss of the ', 239, ' iteration for train:', 0.29143584636128556)\n",
      "('Loss of the ', 239, ' iteration for validation:', 0.30377826435346755)\n",
      "('Loss of the ', 240, ' iteration for train:', 0.29198357644818435)\n",
      "('Loss of the ', 240, ' iteration for validation:', 0.30620300838971254)\n",
      "('Loss of the ', 241, ' iteration for train:', 0.29178847620001197)\n",
      "('Loss of the ', 241, ' iteration for validation:', 0.30398096239945172)\n",
      "('Loss of the ', 242, ' iteration for train:', 0.29114916002754598)\n",
      "('Loss of the ', 242, ' iteration for validation:', 0.3055667018598881)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss of the ', 243, ' iteration for train:', 0.29020833315651678)\n",
      "('Loss of the ', 243, ' iteration for validation:', 0.30360796604905516)\n",
      "('Loss of the ', 244, ' iteration for train:', 0.29024594682077798)\n",
      "('Loss of the ', 244, ' iteration for validation:', 0.30469540048569588)\n",
      "('Loss of the ', 245, ' iteration for train:', 0.29028314374446168)\n",
      "('Loss of the ', 245, ' iteration for validation:', 0.30353953231053205)\n",
      "('Loss of the ', 246, ' iteration for train:', 0.29054782223727876)\n",
      "('Loss of the ', 246, ' iteration for validation:', 0.30507875456856381)\n",
      "('Loss of the ', 247, ' iteration for train:', 0.29080513581386047)\n",
      "('Loss of the ', 247, ' iteration for validation:', 0.30373967741945901)\n",
      "('Loss of the ', 248, ' iteration for train:', 0.29104618219367123)\n",
      "('Loss of the ', 248, ' iteration for validation:', 0.30563152354745654)\n",
      "('Loss of the ', 249, ' iteration for train:', 0.29111593690899379)\n",
      "('Loss of the ', 249, ' iteration for validation:', 0.30393354085514634)\n",
      "('Loss of the ', 250, ' iteration for train:', 0.29124058326806651)\n",
      "('Loss of the ', 250, ' iteration for validation:', 0.30592782363646631)\n",
      "('Loss of the ', 251, ' iteration for train:', 0.29099234967846221)\n",
      "('Loss of the ', 251, ' iteration for validation:', 0.30405447171320532)\n",
      "('Loss of the ', 252, ' iteration for train:', 0.2904024827657789)\n",
      "('Loss of the ', 252, ' iteration for validation:', 0.30513555185696606)\n",
      "('Loss of the ', 253, ' iteration for train:', 0.29016292460308729)\n",
      "('Loss of the ', 253, ' iteration for validation:', 0.3037633620041284)\n",
      "('Loss of the ', 254, ' iteration for train:', 0.29034057764670346)\n",
      "('Loss of the ', 254, ' iteration for validation:', 0.30514181146675962)\n",
      "('Loss of the ', 255, ' iteration for train:', 0.29064934331639825)\n",
      "('Loss of the ', 255, ' iteration for validation:', 0.30392496016846687)\n",
      "('Loss of the ', 256, ' iteration for train:', 0.29109865787574318)\n",
      "('Loss of the ', 256, ' iteration for validation:', 0.30593564902988851)\n",
      "('Loss of the ', 257, ' iteration for train:', 0.29148316680651348)\n",
      "('Loss of the ', 257, ' iteration for validation:', 0.30437070135209343)\n",
      "('Loss of the ', 258, ' iteration for train:', 0.29181116756810865)\n",
      "('Loss of the ', 258, ' iteration for validation:', 0.30667824187437526)\n",
      "('Loss of the ', 259, ' iteration for train:', 0.29146194492860911)\n",
      "('Loss of the ', 259, ' iteration for validation:', 0.30443587654692694)\n",
      "('Loss of the ', 260, ' iteration for train:', 0.29080136951424851)\n",
      "('Loss of the ', 260, ' iteration for validation:', 0.30586800978824713)\n",
      "('Loss of the ', 261, ' iteration for train:', 0.28996472322420513)\n",
      "('Loss of the ', 261, ' iteration for validation:', 0.3040667883346595)\n",
      "('Loss of the ', 262, ' iteration for train:', 0.29006091070741946)\n",
      "('Loss of the ', 262, ' iteration for validation:', 0.30515895410446159)\n",
      "('Loss of the ', 263, ' iteration for train:', 0.29033051856286235)\n",
      "('Loss of the ', 263, ' iteration for validation:', 0.30406118224853557)\n",
      "('Loss of the ', 264, ' iteration for train:', 0.29046394549444665)\n",
      "('Loss of the ', 264, ' iteration for validation:', 0.3055838395880861)\n",
      "('Loss of the ', 265, ' iteration for train:', 0.29057043274702077)\n",
      "('Loss of the ', 265, ' iteration for validation:', 0.30414666913057165)\n",
      "('Loss of the ', 266, ' iteration for train:', 0.2908783510898974)\n",
      "('Loss of the ', 266, ' iteration for validation:', 0.30606370366629981)\n",
      "('Loss of the ', 267, ' iteration for train:', 0.29093455476512087)\n",
      "('Loss of the ', 267, ' iteration for validation:', 0.30442974585883265)\n",
      "('Loss of the ', 268, ' iteration for train:', 0.29123397315314742)\n",
      "('Loss of the ', 268, ' iteration for validation:', 0.30654493850476888)\n",
      "('Loss of the ', 269, ' iteration for train:', 0.29069898742738215)\n",
      "('Loss of the ', 269, ' iteration for validation:', 0.30450469931389429)\n",
      "('Loss of the ', 270, ' iteration for train:', 0.29036860250689428)\n",
      "('Loss of the ', 270, ' iteration for validation:', 0.30573981662830085)\n",
      "('Loss of the ', 271, ' iteration for train:', 0.2900810336402036)\n",
      "('Loss of the ', 271, ' iteration for validation:', 0.30428861591146567)\n",
      "('Loss of the ', 272, ' iteration for train:', 0.29031220793815393)\n",
      "('Loss of the ', 272, ' iteration for validation:', 0.30577548813710764)\n",
      "('Loss of the ', 273, ' iteration for train:', 0.29035382106770408)\n",
      "('Loss of the ', 273, ' iteration for validation:', 0.30440815422680073)\n",
      "('Loss of the ', 274, ' iteration for train:', 0.29024730491528333)\n",
      "('Loss of the ', 274, ' iteration for validation:', 0.30572664659882459)\n",
      "('Loss of the ', 275, ' iteration for train:', 0.29060744273765593)\n",
      "('Loss of the ', 275, ' iteration for validation:', 0.30450847207844517)\n",
      "('Loss of the ', 276, ' iteration for train:', 0.29116735336752941)\n",
      "('Loss of the ', 276, ' iteration for validation:', 0.30669403054772465)\n",
      "('Loss of the ', 277, ' iteration for train:', 0.2912753354570467)\n",
      "('Loss of the ', 277, ' iteration for validation:', 0.30496263686541192)\n",
      "('Loss of the ', 278, ' iteration for train:', 0.29122755121022831)\n",
      "('Loss of the ', 278, ' iteration for validation:', 0.30692706980647111)\n",
      "('Loss of the ', 279, ' iteration for train:', 0.29091580095521302)\n",
      "('Loss of the ', 279, ' iteration for validation:', 0.30490586983552731)\n",
      "('Loss of the ', 280, ' iteration for train:', 0.29036297865437077)\n",
      "('Loss of the ', 280, ' iteration for validation:', 0.30611627201632852)\n",
      "('Loss of the ', 281, ' iteration for train:', 0.28978968463799087)\n",
      "('Loss of the ', 281, ' iteration for validation:', 0.30459181897153004)\n",
      "('Loss of the ', 282, ' iteration for train:', 0.28988510900884223)\n",
      "('Loss of the ', 282, ' iteration for validation:', 0.30572450021635411)\n",
      "('Loss of the ', 283, ' iteration for train:', 0.29012938229168994)\n",
      "('Loss of the ', 283, ' iteration for validation:', 0.30463067888137263)\n",
      "('Loss of the ', 284, ' iteration for train:', 0.29042328968668923)\n",
      "('Loss of the ', 284, ' iteration for validation:', 0.30628630802725448)\n",
      "('Loss of the ', 285, ' iteration for train:', 0.29060602943192965)\n",
      "('Loss of the ', 285, ' iteration for validation:', 0.30487646642833993)\n",
      "('Loss of the ', 286, ' iteration for train:', 0.29112067415325654)\n",
      "('Loss of the ', 286, ' iteration for validation:', 0.30704935553762314)\n",
      "('Loss of the ', 287, ' iteration for train:', 0.29087571475661145)\n",
      "('Loss of the ', 287, ' iteration for validation:', 0.30516178489140205)\n",
      "('Loss of the ', 288, ' iteration for train:', 0.29102611318963589)\n",
      "('Loss of the ', 288, ' iteration for validation:', 0.30712110510333629)\n",
      "('Loss of the ', 289, ' iteration for train:', 0.29056753034783722)\n",
      "('Loss of the ', 289, ' iteration for validation:', 0.30513266862041294)\n",
      "('Loss of the ', 290, ' iteration for train:', 0.28997901838506573)\n",
      "('Loss of the ', 290, ' iteration for validation:', 0.3060754884458195)\n",
      "('Loss of the ', 291, ' iteration for train:', 0.28959708589748123)\n",
      "('Loss of the ', 291, ' iteration for validation:', 0.30477340707175243)\n",
      "('Loss of the ', 292, ' iteration for train:', 0.28975152442750601)\n",
      "('Loss of the ', 292, ' iteration for validation:', 0.30593795285332476)\n",
      "('Loss of the ', 293, ' iteration for train:', 0.29018503817303526)\n",
      "('Loss of the ', 293, ' iteration for validation:', 0.30489949831832569)\n",
      "('Loss of the ', 294, ' iteration for train:', 0.29056378578912045)\n",
      "('Loss of the ', 294, ' iteration for validation:', 0.30676587891937634)\n",
      "('Loss of the ', 295, ' iteration for train:', 0.29095270461743705)\n",
      "('Loss of the ', 295, ' iteration for validation:', 0.30534179294857372)\n",
      "('Loss of the ', 296, ' iteration for train:', 0.29127699223345505)\n",
      "('Loss of the ', 296, ' iteration for validation:', 0.30756049914291561)\n",
      "('Loss of the ', 297, ' iteration for train:', 0.29107529688107625)\n",
      "('Loss of the ', 297, ' iteration for validation:', 0.30556796660983387)\n",
      "('Loss of the ', 298, ' iteration for train:', 0.29080954563685901)\n",
      "('Loss of the ', 298, ' iteration for validation:', 0.30730139651462701)\n",
      "('Loss of the ', 299, ' iteration for train:', 0.28987227776116625)\n",
      "('Loss of the ', 299, ' iteration for validation:', 0.30527333870964379)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XuYHHWd9/33t89zTjIzOQcSIBAQ\nIYEQQERQUAMiKHL0RBCIsCDKvbIX7nqj8Oitqzy48tws3OCC4qqAIBh346JgvCMrYgImISGBBEjI\niWQySWYyhz7/nj9+NU1nMplMDp2eSX9e19VXd1dVV32rq7s+/auqrjLnHCIiIgChchcgIiKDh0JB\nREQKFAoiIlKgUBARkQKFgoiIFCgURESkQKEgIiIFCgWR3TCz1WZ2brnrEDmYFAoiIlKgUBDZS2Z2\nnZmtMrOtZjbHzMYG3c3MfmBmm82s3cxeMbPjg37nm9mrZrbDzNab2VfLOxcifVMoiOwFM/sQ8B3g\nMmAMsAZ4NOj9EeADwNFAQzBMa9Dv34AvOufqgOOBPxzEskUGLFLuAkSGmM8ADznnXgYws68B28xs\nIpAB6oApwF+dc8uLXpcBjjOzxc65bcC2g1q1yACppSCyd8biWwcAOOc68K2Bcc65PwD/G7gX2Gxm\nD5hZfTDop4DzgTVm9n/N7PSDXLfIgCgURPbOBuDwnidmVgM0AusBnHP3OOdOBo7Db0a6Nei+wDl3\nETASeBp4/CDXLTIgCgWR/kXNLNFzA34BXG1mU80sDvwv4EXn3GozO8XMTjWzKNAJJIG8mcXM7DNm\n1uCcywDtQL5scyTSD4WCSP/mAt1Ft7OB/wk8CWwEjgSuCIatBx7E7y9Yg9+s9P2g3+eA1WbWDlyP\n3zchMuiYLrIjIiI91FIQEZEChYKIiBQoFEREpEChICIiBUPuH81NTU1u4sSJ5S5DRGRIeemll7Y4\n55r3NNyQC4WJEyeycOHCcpchIjKkmNmaPQ+lzUciIlJEoSAiIgUKBRERKRhy+xRE5ODJZDKsW7eO\nZDJZ7lJkgBKJBOPHjycaje7T6xUKIrJb69ato66ujokTJ2Jm5S5H9sA5R2trK+vWrWPSpEn7NI6S\nbT4ys4eCyxIu3U1/M7N7gssaLjGzk0pVi4jsm2QySWNjowJhiDAzGhsb96tlV8p9Cj8GZvbT/zxg\ncnCbDdxXwlpEZB8pEIaW/V1eJQsF59x8YGs/g1wEPOK8vwDDzGxMqepZ/uIzvPDgV8hm0qWahIjI\nkFfOo4/GAWuLnq8Luu3CzGab2UIzW9jS0rJPE2tb+QKnr3+Y7q6OfXq9iEglGBKHpDrnHnDOTXfO\nTW9u3uO/tPtk0SoAUsmuA1maiJTQ9u3b+dd//de9ft3555/P9u3b+x3m9ttv59lnn93X0vpUW1t7\nQMdXDuUMhfXAhKLn44NuJRGKJgBId3eWahIicoDtLhSy2Wy/r5s7dy7Dhg3rd5g777yTc889d7/q\nOxSV85DUOcBNZvYocCrQ5pzbWKqJhePVAKSTCgWRfXHHb5bx6ob2AzrO48bW842Pv2e3/W+77Tbe\neOMNpk6dSjQaJZFIMHz4cFasWMHrr7/OJz7xCdauXUsymeTLX/4ys2fPBt49R1pHRwfnnXce73//\n+/nzn//MuHHj+PWvf01VVRWzZs3iggsu4JJLLmHixIlcddVV/OY3vyGTyfDLX/6SKVOm0NLSwqc/\n/Wk2bNjA6aefzu9//3teeuklmpqa+p0v5xz/8A//wG9/+1vMjK9//etcfvnlbNy4kcsvv5z29nay\n2Sz33Xcf73vf+7jmmmtYuHAhZsYXvvAFbrnllgP6Pu+NUh6S+gvgBeAYM1tnZteY2fVmdn0wyFzg\nTWAV/rq2f1eqWgDCMb/5SC0FkaHju9/9LkceeSSLFi3i+9//Pi+//DI//OEPef311wF46KGHeOml\nl1i4cCH33HMPra2tu4xj5cqV3HjjjSxbtoxhw4bx5JNP9jmtpqYmXn75ZW644QbuuusuAO644w4+\n9KEPsWzZMi655BLefvvtAdX9q1/9ikWLFrF48WKeffZZbr31VjZu3MjPf/5zPvrRjxb6TZ06lUWL\nFrF+/XqWLl3KK6+8wtVXX72P79aBUbKWgnPuyj30d8CNpZp+b9GgpZBJaZ+CyL7o7xf9wTJjxoyd\n/pR1zz338NRTTwGwdu1aVq5cSWNj406vmTRpElOnTgXg5JNPZvXq1X2O++KLLy4M86tf/QqA559/\nvjD+mTNnMnz48AHV+fzzz3PllVcSDocZNWoUZ511FgsWLOCUU07hC1/4AplMhk984hNMnTqVI444\ngjfffJMvfelLfOxjH+MjH/nIwN+QEhgSO5oPhHC8BoCsQkFkyKqpqSk8/uMf/8izzz7LCy+8wOLF\ni5k2bVqff9qKx+OFx+FweLf7I3qG62+Y/fWBD3yA+fPnM27cOGbNmsUjjzzC8OHDWbx4MWeffTb3\n338/1157bUmmPVAVEwrRhG8pKBREho66ujp27NjRZ7+2tjaGDx9OdXU1K1as4C9/+csBn/4ZZ5zB\n448/DsDvfvc7tm3bNqDXnXnmmTz22GPkcjlaWlqYP38+M2bMYM2aNYwaNYrrrruOa6+9lpdffpkt\nW7aQz+f51Kc+xbe+9S1efvnlAz4fe6Nizn0US/hfGLl0d5krEZGBamxs5IwzzuD444+nqqqKUaNG\nFfrNnDmT+++/n2OPPZZjjjmG00477YBP/xvf+AZXXnklP/3pTzn99NMZPXo0dXV1e3zdJz/5SV54\n4QVOPPFEzIzvfe97jB49mp/85Cd8//vfJxqNUltbyyOPPML69eu5+uqryefzAHznO9854POxN8xv\n2h86pk+f7vblymub16xg5MOn8pcTvsVpF3+pBJWJHHqWL1/OscceW+4yyiaVShEOh4lEIrzwwgvc\ncMMNLFq0qNxl7VFfy83MXnLOTd/TayumpRCv8puP1FIQkYF6++23ueyyy8jn88RiMR588MFyl1Ry\nFRQK/p+GLqNQEJGBmTx5Mn/729926tba2so555yzy7DPPffcLkc+DUWVEwrBjmYUCiKyHxobG4fE\nJqR9VTFHH1kkTt6ZQkFEpB8VEwqYkbIYZBUKIiK7UzmhAKSIYdlUucsQERm0KioU0hYjlNMFyEVE\ndqfCQiFBOKtQEDlU9VzPYMOGDVxyySV9DnP22Wezp/86/cu//AtdXe+e/WAg12fYG7NmzeKJJ544\nYOM7kCoqFDKhOKG8QkHkUDd27Nj9Wun2DoWBXJ/hUFExh6QCZENxIjntUxDZJ7+9Dd555cCOc/R7\n4bzv7rb3bbfdxoQJE7jxRn9C5W9+85tEIhHmzZvHtm3byGQyfOtb3+Kiiy7a6XWrV6/mggsuYOnS\npXR3d3P11VezePFipkyZQnf3uweb3HDDDSxYsIDu7m4uueQS7rjjDu655x42bNjABz/4QZqampg3\nb17h+gxNTU3cfffdPPTQQwBce+21fOUrX2H16tW7vW7Dnjz33HN89atfJZvNcsopp3DfffcRj8e5\n7bbbmDNnDpFIhI985CPcdddd/PKXv+SOO+4gHA7T0NDA/Pnz9+Vd71dFhUIuFCeiHc0iQ8bll1/O\nV77ylUIoPP744zzzzDPcfPPN1NfXs2XLFk477TQuvPBCzKzPcdx3331UV1ezfPlylixZwkknnVTo\n9+1vf5sRI0aQy+U455xzWLJkCTfffDN333038+bN2+ViOi+99BIPP/wwL774Is45Tj31VM466yyG\nDx/OypUr+cUvfsGDDz7IZZddxpNPPslnP/vZfucvmUwya9YsnnvuOY4++mg+//nPc9999/G5z32O\np556ihUrVmBmhU1Xd955J8888wzjxo07oJuzilVWKIQTRNN9n3FRRPagn1/0pTJt2jQ2b97Mhg0b\naGlpYfjw4YwePZpbbrmF+fPnEwqFWL9+PZs2bWL06NF9jmP+/PncfPPNAJxwwgmccMIJhX6PP/44\nDzzwANlslo0bN/Lqq6/u1L+3559/nk9+8pOFU3hffPHF/OlPf+LCCy8c8HUbir322mtMmjSJo48+\nGoCrrrqKe++9l5tuuolEIsE111zDBRdcwAUXXAD4s7bOmjWLyy67rHD9hwOtovYp5MJxoi5d7jJE\nZC9ceumlPPHEEzz22GNcfvnl/OxnP6OlpYWXXnqJRYsWMWrUqD6vo7Anb731FnfddRfPPfccS5Ys\n4WMf+9g+jafHQK/bMBCRSIS//vWvXHLJJfzHf/wHM2fOBOD+++/nW9/6FmvXruXkk0/u80pz+6ui\nQsGFE8ScNh+JDCWXX345jz76KE888QSXXnopbW1tjBw5kmg0yrx581izZk2/r//ABz7Az3/+cwCW\nLl3KkiVLAGhvb6empoaGhgY2bdrEb3/728JrdncdhzPPPJOnn36arq4uOjs7eeqppzjzzDP3ed6O\nOeYYVq9ezapVqwD46U9/yllnnUVHRwdtbW2cf/75/OAHP2Dx4sUAvPHGG5x66qnceeedNDc3s3bt\n2n2e9u5U1OajfCRBTC0FkSHlPe95Dzt27GDcuHGMGTOGz3zmM3z84x/nve99L9OnT2fKlCn9vv6G\nG27g6quv5thjj+XYY4/l5JNPBuDEE09k2rRpTJkyhQkTJnDGGWcUXjN79mxmzpzJ2LFjmTdvXqH7\nSSedxKxZs5gxYwbgdzRPmzZtQJuK+pJIJHj44Ye59NJLCzuar7/+erZu3cpFF11EMpnEOcfdd98N\nwK233srKlStxznHOOedw4okn7tN0+1PS6ymY2Uzgh0AY+JFz7ru9+h8OPAQ0A1uBzzrn1vU3zn29\nngLA3/7PbI7cMIfab2wkFOp7p5SIvKvSr6cwVO3P9RRKtvnIzMLAvcB5wHHAlWZ2XK/B7gIecc6d\nANwJlPaSQ9EqEqRJZnMlnYyIyFBVyn0KM4BVzrk3nXNp4FHgol7DHAf8IXg8r4/+B1a0ipjlSKYy\nJZ2MiAjAjTfeyNSpU3e6Pfzww+Uuq1+l3KcwDijeC7IOOLXXMIuBi/GbmD4J1JlZo3Nup13qZjYb\nmA1w2GGH7XNBFvV/JEl2d0Ldnv9UIiLgnNvtfwCkf/fee+9Bn+b+7hIo99FHXwXOMrO/AWcB64Fd\ntu045x5wzk13zk1vbm7e54mFYkWhICJ7lEgkaG1t3e8VjRwczjlaW1tJJBL7PI5SthTWAxOKno8P\nuhU45zbgWwqYWS3wKedcaf6mB4SDUMgkFQoiAzF+/HjWrVtHS0tLuUuRAUokEowfP36fX1/KUFgA\nTDazSfgwuAL4dPEAZtYEbHXO5YGv4Y9EKplwzF+SM61QEBmQaDTKpEmTyl2GHEQl23zknMsCNwHP\nAMuBx51zy8zsTjO7MBjsbOA1M3sdGAV8u1T1AITjPhQyya49DCkiUplK+uc159xcYG6vbrcXPX4C\nOGgnFY/2hEJKoSAi0pdy72g+qCJBKOTSuk6ziEhfKioUYlVBKGjzkYhInyorFNRSEBHpV0WFQrza\nX781n1FLQUSkL5UVCgl/YQynloKISJ8qKhR6/tHsMgoFEZG+VFQoEAnOd6RQEBHpU4WFQpw8Btl9\nv+SeiMihrLJCwYw0UUyhICLSp8oKBSBtcSynUBAR6UsFhkKMsEJBRKRPFRcKWYsTzqXKXYaIyKBU\ncaGQCcXVUhAR2Y2KC4VcKE44r5aCiEhfKi4UsuEqYgoFEZE+VVwo5MJxok6hICLSl4oLBRdJEFMo\niIj0qeJCIR9OECONc67cpYiIDDoVFwoukiBBmnQuX+5SREQGnZKGgpnNNLPXzGyVmd3WR//DzGye\nmf3NzJaY2fmlrAeAaBUJ0iTTCgURkd5KFgpmFgbuBc4DjgOuNLPjeg32deBx59w04ArgX0tVT6Gu\nSIIEGbozuVJPSkRkyCllS2EGsMo596ZzLg08ClzUaxgH1AePG4ANJawHAItVEbcM3elMqSclIjLk\nlDIUxgFri56vC7oV+ybwWTNbB8wFvtTXiMxstpktNLOFLS0t+1VUKOqvqZDq1iU5RUR6K/eO5iuB\nHzvnxgPnAz81s11qcs494Jyb7pyb3tzcvF8T7Ln6WirZuV/jERE5FJUyFNYDE4qejw+6FbsGeBzA\nOfcCkACaSlgTobi/TnOmW6EgItJbKUNhATDZzCaZWQy/I3lOr2HeBs4BMLNj8aGwf9uH9iAStBQy\nKYWCiEhvJQsF51wWuAl4BliOP8pomZndaWYXBoP9PXCdmS0GfgHMciX+V1k0UQ1AJqnrNIuI9BYp\n5cidc3PxO5CLu91e9PhV4IxS1tBbNO5DIZvWjmYRkd7KvaP5oIsELYVsSqEgItJbxYVCLOF3NOfV\nUhAR2UUFhoJvKeTT2qcgItJbxYVCNN7TUlAoiIj0VnGhQCQBgMsoFEREequ8UAhOc0E2Wd46REQG\nocoLhaClQEahICLSW8WGgmW1+UhEpLfKC4VQiBQxLKeWgohIb5UXCkDGYoS1T0FEZBeVGQqhOGG1\nFEREdlGZoWBxwvlUucsQERl0KjIUsuE4EYWCiMguKjIUcqGEQkFEpA8VGQr5cJyoQkFEZBcVGQq5\ncIKoUyiIiPRWkaHgIgnipMnk8uUuRURkUKnQUKgiQZpkJlfuUkREBpWKDAWiCRKWoVuhICKyk5KG\ngpnNNLPXzGyVmd3WR/8fmNmi4Pa6mW0vZT0FQUshldHmIxGRYpFSjdjMwsC9wIeBdcACM5vjnHu1\nZxjn3C1Fw38JmFaqenaqLVpFFSla1FIQEdlJKVsKM4BVzrk3nXNp4FHgon6GvxL4RQnrKQjFgs1H\nqezBmJyIyJBRylAYB6wter4u6LYLMzscmAT8YTf9Z5vZQjNb2NLSst+FhaL+Os3JZNd+j0tE5FAy\nWHY0XwE84Zzrc3uOc+4B59x059z05ubm/Z5YKO6vvpZJdu73uEREDiWlDIX1wISi5+ODbn25goO0\n6QggEvMthUxKLQURkWKlDIUFwGQzm2RmMfyKf07vgcxsCjAceKGEtewkEg9CQS0FEZGdlCwUnHNZ\n4CbgGWA58LhzbpmZ3WlmFxYNegXwqHPOlaqW3npCIZvSJTlFRIqV7JBUAOfcXGBur26393r+zVLW\n0JdYoicUtPlIRKTYYNnRfFBFq2oAyKXVUhARKTagUDCzI80sHjw+28xuNrNhpS2tdKLB5qO8QkFE\nZCcDbSk8CeTM7CjgAfxRRT8vWVUlZlF/SKrLaPORiEixgYZCPthx/Eng/3PO3QqMKV1ZJRbxoZDP\nqKUgIlJsoKGQMbMrgauA/wi6RUtT0kEQTfj7dLK8dYiIDDIDDYWrgdOBbzvn3jKzScBPS1dWiQUt\nBbJqKYiIFBvQIanBmU1vBjCz4UCdc+6fS1lYSQUtBcuqpSAiUmygRx/90czqzWwE8DLwoJndXdrS\nSihoKSgURER2NtDNRw3OuXbgYuAR59ypwLmlK6vEQiEyRAnlFAoiIsUGGgoRMxsDXMa7O5qHtEwo\nplAQEelloKFwJ/4cRm845xaY2RHAytKVVXoZSxDJpcpdhojIoDLQHc2/BH5Z9PxN4FOlKupgyIbi\nhBUKIiI7GeiO5vFm9pSZbQ5uT5rZ+FIXV0q5cJxIXpuPRESKDXTz0cP4ayGMDW6/CboNWblwgmg+\nXe4yREQGlYGGQrNz7mHnXDa4/RjY/+tillEunCDmUuTzB+0yDiIig95AQ6HVzD5rZuHg9lmgtZSF\nlZoLx6myNMlsn5eFFhGpSAMNhS/gD0d9B9gIXALMKlFNB4WLVpEgTXdaoSAi0mNAoeCcW+Ocu9A5\n1+ycG+mc+wRD/OgjIgnipOlSKIiIFOzPldf+x54GMLOZZvaama0ys9t2M8xlZvaqmS0zs4N2jQaL\nVpEwhYKISLH9uUaz9dvTLAzcC3wYWAcsMLM5wcn1eoaZDHwNOMM5t83MRu5HPXslFPObj95JZw/W\nJEVEBr39aSns6bCdGcAq59ybzrk08ChwUa9hrgPudc5tA3DObd6PevZKOFZFggydKYWCiEiPflsK\nZraDvlf+BlTtYdzjgLVFz9cBp/Ya5uhgOv8NhIFvOuf+aw/jPSDC8RoSpOlMKhRERHr0GwrOubqD\nMP3JwNnAeGC+mb3XObe9eCAzmw3MBjjssMMOzITj1YTM0d2tC+2IiPTYn81He7IemFD0fHzQrdg6\nYI5zLuOcewt4HR8SO3HOPeCcm+6cm97cfGD+MxdNVAOQSnYckPGJiBwKShkKC4DJZjbJzGLAFfhT\nZRR7Gt9KwMya8JuT3ixhTQWxeA0Aqe6ugzE5EZEhoWSh4JzLAjfhT7m9HHjcObfMzO40swuDwZ7B\n/1v6VWAecKtz7qD8Uzpa5UMh062WgohIj/05JHWPnHNzgbm9ut1e9Njh/++wx/88HGgWqwUgm9px\nsCctIjJolXLz0eAW8y2FvPYpiIgUVHAo+JaCS3eWuRARkcGjgkPBtxRcSi0FEZEeFR8KllYoiIj0\nqNxQiPv/5YUyOiRVRKRH5YZC0FIIZ7VPQUSkR+WGQjhGjjCRrFoKIiI9KjcUzEiHq4nkdO4jEZEe\nlRsKQDZcRTzfTS6/p7OAi4hUhsoOhUgNNZakSxfaEREBKjwU8tFqqknSmdIlOUVEoMJDwUV9S6Gt\nO1PuUkREBoWKDoVQvJYakrR2pspdiojIoFDRoRCpqqOaJK0d6XKXIiIyKFR0KMSq66mxJK0daimI\niEClh0JVHdWkaO1US0FEBCo8FELxWmosyZYdaimIiECFhwKxGkI4duxoL3clIiKDQsWHAkBXR1uZ\nCxERGRxKGgpmNtPMXjOzVWZ2Wx/9Z5lZi5ktCm7XlrKeXcTrAUh3bjuokxURGawipRqxmYWBe4EP\nA+uABWY2xzn3aq9BH3PO3VSqOvpVNxqAaNfmskxeRGSwKWVLYQawyjn3pnMuDTwKXFTC6e29+nEA\nNGRaSGZ0qgsRkVKGwjhgbdHzdUG33j5lZkvM7Akzm9DXiMxstpktNLOFLS0tB67C+jEAjLGtbNVh\nqSIiZd/R/BtgonPuBOD3wE/6Gsg594Bzbrpzbnpzc/OBm3qshky0gdHWqn81i4hQ2lBYDxT/8h8f\ndCtwzrU653r+JPAj4OQS1tOnTO0YxthWtuj8RyIiJQ2FBcBkM5tkZjHgCmBO8QBmNqbo6YXA8hLW\n0yerH8to26qWgogIJQwF51wWuAl4Br+yf9w5t8zM7jSzC4PBbjazZWa2GLgZmFWqenYnMnw8Y2yr\nzn8kIkIJD0kFcM7NBeb26nZ70eOvAV8rZQ17Ehk2jmZrY9uOznKWISIyKJR7R3PZWXBYamb7+j0M\nKSJy6Kv4UKB+LADWvrHMhYiIlJ9CIWgpxLo2lLkQEZHyUygELYWq7k1lLkREpPwUCol6UqFq6tIt\nOOfKXY2ISFkpFICuxChG0sqOVLbcpYiIlJVCAUjXjAn+q6A/sIlIZVMoAPm6nn816w9sIlLZFApA\nuGEcI9lGa3tXuUsRESkrhQIQHzGesDk6t+oPbCJS2RQKQHXzYQBktykURKSyKRSA6LDxALg2hYKI\nVDaFAhT+wBbu1KkuRKSyKRQAqoaTIk6i651yVyIiUlYKBQAztkebqU1vLnclIiJlpVAIdMRHMizT\nUu4yRETKSqEQSFWNpsltIZfX+Y9EpHIpFAK52jGMYhvbOpPlLkVEpGwUCgGrH0fUcmzdrMNSRaRy\nlTQUzGymmb1mZqvM7LZ+hvuUmTkzm17KevpTPXIiAG3rV5arBBGRsitZKJhZGLgXOA84DrjSzI7r\nY7g64MvAi6WqZSCGTzwBgPSGpeUsQ0SkrErZUpgBrHLOvemcSwOPAhf1Mdz/A/wzUNaN+cPGHEmH\nqyLaurycZYiIlFUpQ2EcsLbo+bqgW4GZnQRMcM79Z38jMrPZZrbQzBa2tJTmsFELhVgTmciw9tdL\nMn4RkaGgbDuazSwE3A38/Z6Gdc494Jyb7pyb3tzcXLKaWqqPYmzqTdBlOUWkQpUyFNYDE4qejw+6\n9agDjgf+aGargdOAOeXc2dw1fAq1dOK2v12uEkREyqqUobAAmGxmk8wsBlwBzOnp6Zxrc841Oecm\nOucmAn8BLnTOLSxhTf3Kjj8VgI4lc/YwpIjIoalkoeCcywI3Ac8Ay4HHnXPLzOxOM7uwVNPdHyMm\nTWNJfhL2t3/XJiQRqUgl3afgnJvrnDvaOXekc+7bQbfbnXO7/BR3zp1dzlYCwCmThvO0nUPt9hWw\n8vflLEVEpCz0j+Yi8UiYtqMvZSWH4Z6+HnTRHRGpMAqFXs494XC+mLqZXKoLnrwGcplylyQictAo\nFHr5yHtGM/yw9/BPuevg7RfgyWshly13WSIiB4VCoZdwyLj7shN5JnQm90avglefDloMCgYROfRF\nyl3AYHR4Yw0/uXoGn34wT6QqxBdffRjM4OIfQVhvmYgcurSG240TJwzjwaumc/XDjlAtXLfsYcDg\n4gcVDCJyyNLarR/vO7KJh2adwjU/AVftmL3sx76HgkFEDlFas+3BGUc18eOrZ/CFHxsu4fjisp/4\nTUmffEDBICKHHK3VBuC0Ixp55AszmPWw4WKO65c+4g9V/dS/QSRW7vJERA4YHX00QNMnjuCRa2Zw\nb/oC7oleDcvnwKOfhkx3uUsTETlgFAp74aTDhvOz607l37Ln87/C1+NWPQv/fgmkdpS7NBGRA0Kh\nsJdOGD+Mx754Gk+FPsw/2s24t1+ARy6Crq3lLk1EZL8pFPbBlNH1PHH96fwpcTZfyv89+Y2vwIMf\nhE2vlrs0EZH9olDYR4c31vDE9e9jRcP7uTL9dVLdXfCjc0Gn3RaRIUyhsB9GNyR4/Iun0zXqZD7Y\n/g1a6qbAr2+En3wctqwqd3kiIntNobCfRtTE+Pl1p3LkkZOZseEWnh5/K27jYrjvdHj2Dki2lbtE\nEZEBUygcAHWJKA/POoXZZx3FV1ZN4zOJe2mb9DF4/m744Ynwwr2QSZa7TBGRPVIoHCCRcIivnXcs\nD35+Oq93VjF9+WU8dtK/kx8zDZ75R7j7WPjd12Hzcu1zEJFBy9wQW0FNnz7dLVxY1qt27tHWzjT/\n89dL+c8lG5kyuo7vTW/nhPXXpnXOAAASxElEQVSPwYr/BJeDEUfC5A/D4WfAuJOgbiyElM8iUjpm\n9pJzbvoehytlKJjZTOCHQBj4kXPuu736Xw/cCOSADmC2c67f4zqHQij0+K+lG/n23OWs3drN+45s\n5Esz6jkt/QK24j9hzZ8hG/wbOlrtg6LxSGiaDI1HQcN4SAyDRANUDYNYrT/nkshQkM+Dy+/5/GDO\nQT7nP9sdm6B2NHRuhrrRRePKQSgM6S6IVsG2t6BmpD+rwBEfhK4t0DgZInE/nu7tEK+DlhVQN8a3\nzhvG+26xGsh0QSQB77ziX/P2i1A9AoYdDvFa/xozvz8wl4FUu3+c6fb/Rxp3kq+leoSvuW40tG+E\nTCdsXOJf37ICjjgbulphzFRoXwdVI2D9S1DdCG/+EUa/1z+f/GE/7lHvga1v+uHeeM7/WHz9v2Ds\nNNj6hp/XaZ/178U+KHsomFkYeB34MLAOWABcWbzSN7N651x78PhC4O+cczP7G+9QCgWAVDbHT19Y\nw4N/epNN7SkOb6xm5ntG88GjhjEt/CbxrSugddW7t21rfGuiNwv7D2ykyn+Qo1X+gx1JQDRR9Djo\nH0lAOBZ0j+96TxAwoZAPn2wKEvWQz0K0xt8nGiCf8dPMZyBeD+kO371rq/9wt2+A2pH+X93VIyDZ\n7r986U6IVfvp9HyILeRrAj+P+bzvl8v4ecum/Jc2l/bDZZN+vpPb/bQ7NkH9WD/NhvHQvh7qx/n3\nbNgE/0VsnuJXAiOP8+9n41HQstx33/qmD9+W5X4lsmmZD+Etr0PzMcF4J8CmpX78m1f48bZv8CuM\nZBvUNPmVULzBTw8Hr/3Wz0c47t+b8af45/E6P0/5LHRv8yvAzs1+3B2bYfhEPw9Vw2HLyndXJk1H\n+5pGnwCtK2Hksf4/MKOO8yuyujF+pTLmRP984pl+3kYfD+sW+ppXPgtjTvDjG3cytK3z87h5hZ/u\npqX+vVu/0M9bR1BXusMvzx2b/Oehe5v/zLS+4Zdf1xa/TJqP8SvOSMIv61DELyeXhx3v+B867Rv8\ncJ0tMOwwv5yGH+7HNewwX9vww/28NYyD7W/7lX3nZr982tb65fPOUj+elhW+5vb1EIr6zyTml0F1\nk195N4yHrW/59z7V7mt2eV+zy/nllt7h682l+/7SWsiP1+X9uEuhp65QxH8+dqe60QdLrM7Xfe43\n4f237NskB0EonA580zn30eD51wCcc9/ZzfBXAp93zp3X33iHWij0SGVz/GbxRuYs3sCfV20hm3dE\nQsbx4xo4cXwDR42s5ciRtRw+LMrIzAaiXZv8Sqh7u79Pbvcr3mzSr2gy3f4+293H8/S7w2WTlOyD\nfSAUvhzBlzwch1zKh0I+61c6mS6/ktnpvsb/MovV+hVZ8ety6aLx9TwPvnw9z3um27NS6Vlp9Nzv\njVAkWJGw+xXNwN8QX0/hfjfi9X6l13Pf+32sH+9/ndaNhR0b3l2p9Axf0+xXNsMnwY6N7/7aTTT4\nIKga5n8Nx+v8Z6imKfgxEoR2crv/fOXSPsizKb8Cy3T5YE1uD4Jgte++/W0/re1rfFBvfcuH3NY3\nfbhtWQUTZviQG/1eWLcARkzygTHmRB/0Y6f5YDj8DD/eI86CDX/zIffWfKgd5cc/8jj/A2LU8X7e\nmo72049W+9fVNPnvy4gjfHg3TPCfoVwGOt7xIQf+MxVN+Pe2dpRvsdQ0+XFE4tC5xYdUz4+VdAdM\nOM2/741HwYZFft43LfU1tq2D8dN9OE58P7S85oN87Ys+1N55xYdg+3of9O0bgnl5x/8QeG0uTPqA\n/xGxL5+sQRAKlwAznXPXBs8/B5zqnLup13A3Av8DiAEfcs6t7GNcs4HZAIcddtjJa9asKUnNB0tb\nd4aX1mxlweptLFy9leUbd9CRevfXghk01sRpqo1RG49QE49Qm4hQGwvu4xGqY2FikZC/hUPEo2F/\n39Mt6B4LG7FQjgQZYpYm7rLEXJpoJETIwHp+xUYSPnzCMf/FtlDwPOqPnApH/PNYbbDSGO5/AdaO\n8r8MEw1+JZOo9+HVs/IORd5d+eaz/uZyFFZ62bT/gqXa/Yqrp1WQ3uFbKN3b/DTa1vovVusb0HSU\n/2XdNNn/8h39Xv/rf8xU2LgYxk71X7BRx/v7sdN8q6D5GP8FHX1C8Ev8vUGr4ljff8QRfiU18lj/\ny7nxKP/FrB/jV2I1Tb57TZOfx7oxvpXVMM6vZC3kN210bfUr0p73LZfxK91M0t/veAdqGqFtfdBq\n2ORbMm1r/X3rG35TYssKX8PmV4N5WernrfWN4Nf/2ndbNo1H+Xkdc6KvecQk/54mhr3bmmtb60Mi\nud1vosilfcsSfO094ZlNvtuis1Bw62PTZc+6Q5s1h4QhEwpFw38a+Khz7qr+xjtUWwr9cc6xqT3F\nqs0drN3WxTttSTa1J2ntTNOZytLRc0tm6Uxl6Uzv5S/ZfkRCRihkREJGOLgVHpsRDhuRkA+QSCjk\n+4eNkO38mvAu4wjtPN7CuIpeG/bd/TAhwiEIh0K71JTN5enK5Aib0ZnOUZ+IkMzkaKiK0pnOsSOZ\nIZ3NM6w6RkcqS30iyvbuNKPrE7R1Z6hPRNnWlWbcsCrSuTyxcIi27gzVsTAdqRzRsPngjUfIO0d3\nOkd3xt+S6RzxaJhh1VHikTDhkN/qlc3n2ZHM8urGdjZs7+bt1i6q4xHOnNzEcWPqqYqFfXCHwyQz\nOTbvSNEZBH/xOtTMsKCbFXcrek7RMAB5Bx3JLN3pLPVVURprYzTWxBlRE6OtO8PmHUladqRIZvKM\nqIkxpiFBPNL3dui+1ud1Cb8fYEcySyqbI5NzJDM5utI5OlNZ4tEwYxsSjGmoojYeoTuToyudJZ3N\nk8s7cs6RzTvyeUckHKKxJkYiGqY9mcE5V8gSB+SD4fN5gnsHBsOrY4yojpGIhWjvzgTjg1zesaUj\nxab2JFs6UsQjYcYNr+LwxmoOG1GNmdGVztKdztGRytKV9nXHwiHqqyLUJ6LUJSJ0pf0y2dSeZHN7\nkng0zOEjqjlmdB3DqmPk867wGehMZWnvzrIjmcHMGDesilENceKRMJmcn+ds3rFlR4qWjhQdySxV\nsTDDq2Mc3lhNIurf+0wuT2dQU3cmR3c6RyaXZ0xDFSPr4oRCfmFkc3laO9Nsbk+xpTNFIhJmeE2U\nI5pqiUX2/YCUgYZCKa+nsB6YUPR8fNBtdx4F7ithPYOWmTG6IcHohsSAhs/l/Zc0nc2TyuZJZ/Ok\nc7l3H2fzpHP5nftn86RyRf2zeXLOkcvnC1/gbN4VPuDFz3OF7nlyed59jXNkc65oXP553g3gtb2m\ntz96AimVzRMOGbm8K9yXWmNNjCOaazhl0gi2d2X4+Ytvk8rmSz5dKZ1ENEQys+dlOJDPmBmMqI7R\nmc72O85YJMSo+jidqRzbutJ9HrVeFQ1zx0Xv4bLpE3bteQCVMhQWAJPNbBI+DK4APl08gJlNLtpc\n9DFgl01HsqtwyP+yrYmXu5IDpyckCoGS6/nFmSdsRnUsQs454pEQnams/+XZnaEm2JQGkMzkSURD\ndKSy1MQibOlMMawqRnsyQ0NVlHfakiSiYdK5PPWJCN3pHLWJCNm8oyOZZUcySyRsVEXD/hYLE4+E\nSGXzbO/KFMIvZP5/KbWxCPVVEazo53Yyk6NlR6rwSzCVzROLhBhZFy/8Au/5vjvnnzh2/vXsnNtp\nGOcHKvQ3/B8m45EQO5JZWjtTtHamae1IMaw6xsi6OM11cRLRMK0daTa2dfcZvH2teJxztCezwTQi\nJKJhwiEjEQ1TEw9THfOttA3bu9mwPUl3Jkd1zL9fsUioENA9Lb10Ns+WjrRv2VVHCfVq9RjFrU0I\nmZF3sL0rzdZO/7r6qijRsG+thsxorI0zuiFBU22MZCbPum1drGntYu3WLkJmJKKh4HMRCWoOk8rm\nC7/225NZqqJhRtXHGVWfYGRdnO5MjtWtXSxd30Zbd4aqqH+db/FFqE9EqEtEyeUdG7Z3s6k9STKb\noyoaJhS0hJuD970m7j9brZ1p3mrp5J32JLXxMLXxKLWJCDXBeKuC93ZDW5J1W7uC4SI01sRoDupq\nqo2RyuRp6Ujx8pptTB5Zu+9fsgEq9SGp5wP/gj8k9SHn3LfN7E5goXNujpn9EDgXyADbgJucc8v6\nG+ehuPlIRKTUBsPmI5xzc4G5vbrdXvT4y6WcvoiI7B39jVZERAoUCiIiUqBQEBGRAoWCiIgUKBRE\nRKRAoSAiIgUKBRERKRhyF9kxsxZgX8+I1wRsOYDllJPmZXDSvAxOmhc43DnXvKeBhlwo7A8zWziQ\nf/QNBZqXwUnzMjhpXgZOm49ERKRAoSAiIgWVFgoPlLuAA0jzMjhpXgYnzcsAVdQ+BRER6V+ltRRE\nRKQfCgURESmomFAws5lm9pqZrTKz28pdz94ys9Vm9oqZLTKzhUG3EWb2ezNbGdwPL3edfTGzh8xs\ns5ktLerWZ+3m3RMspyVmdlL5Kt/Vbublm2a2Plg2i4KLS/X0+1owL6+Z2UfLU/WuzGyCmc0zs1fN\nbJmZfTnoPuSWSz/zMhSXS8LM/mpmi4N5uSPoPsnMXgxqfszMYkH3ePB8VdB/4n4X4S+kfWjf8Fd+\newM4AogBi4Hjyl3XXs7DaqCpV7fvAbcFj28D/rncde6m9g8AJwFL91Q7cD7wW/xVJ08DXix3/QOY\nl28CX+1j2OOCz1ocmBR8BsPlnoegtjHAScHjOuD1oN4ht1z6mZehuFwMqA0eR4EXg/f7ceCKoPv9\nwA3B478D7g8eXwE8tr81VEpLYQawyjn3pnMuDTwKXFTmmg6Ei4CfBI9/AnyijLXslnNuPrC1V+fd\n1X4R8Ijz/gIMM7MxB6fSPdvNvOzORcCjzrmUc+4tYBX+s1h2zrmNzrmXg8c7gOXAOIbgculnXnZn\nMC8X55zrCJ5Gg5sDPgQ8EXTvvVx6ltcTwDlWfNHwfVApoTAOWFv0fB39f2gGIwf8zsxeMrPZQbdR\nzrmNweN3gFHlKW2f7K72obqsbgo2qzxUtBlvSMxLsMlhGv5X6ZBeLr3mBYbgcjGzsJktAjYDv8e3\nZLY757LBIMX1FuYl6N8GNO7P9CslFA4F73fOnQScB9xoZh8o7ul8+3FIHl88lGsP3AccCUwFNgL/\nb3nLGTgzqwWeBL7inGsv7jfUlksf8zIkl4tzLuecmwqMx7dgphzM6VdKKKwHJhQ9Hx90GzKcc+uD\n+83AU/gPy6aeJnxwv7l8Fe613dU+5JaVc25T8EXOAw/y7qaIQT0vZhbFr0R/5pz7VdB5SC6XvuZl\nqC6XHs657cA84HT85rpI0Ku43sK8BP0bgNb9mW6lhMICYHKwBz+G3yEzp8w1DZiZ1ZhZXc9j4CPA\nUvw8XBUMdhXw6/JUuE92V/sc4PPB0S6nAW1FmzMGpV7b1j+JXzbg5+WK4AiRScBk4K8Hu76+BNud\n/w1Y7py7u6jXkFsuu5uXIbpcms1sWPC4Cvgwfh/JPOCSYLDey6VneV0C/CFo4e27cu9tP1g3/NET\nr+O3z/1TuevZy9qPwB8tsRhY1lM/ftvhc8BK4FlgRLlr3U39v8A33zP47aHX7K52/NEX9wbL6RVg\nernrH8C8/DSodUnwJR1TNPw/BfPyGnBeuesvquv9+E1DS4BFwe38obhc+pmXobhcTgD+FtS8FLg9\n6H4EPrhWAb8E4kH3RPB8VdD/iP2tQae5EBGRgkrZfCQiIgOgUBARkQKFgoiIFCgURESkQKEgIiIF\nCgWpWGbWEdxPNLNPH+Bx/2Ov538+kOMXKRWFgghMBPYqFIr+Xbo7O4WCc+59e1mTSFkoFETgu8CZ\nwTn3bwlOSPZ9M1sQnEztiwBmdraZ/cnM5gCvBt2eDk5SuKznRIVm9l2gKhjfz4JuPa0SC8a91Pz1\nMS4vGvcfzewJM1thZj/b37NdiuyLPf3aEakEt+HPu38BQLByb3POnWJmceC/zex3wbAnAcc7f8pl\ngC8457YGpyRYYGZPOuduM7ObnD+pWW8X40/QdiLQFLxmftBvGvAeYAPw38AZwPMHfnZFdk8tBZFd\nfQR/np9F+FMwN+LPjwPw16JAALjZzBYDf8GfmGwy/Xs/8AvnT9S2Cfi/wClF417n/AncFuE3a4kc\nVGopiOzKgC85557ZqaPZ2UBnr+fnAqc757rM7I/4c9Hsq1TR4xz6fkoZqKUgAjvwl3Hs8QxwQ3A6\nZszs6ODstL01ANuCQJiCv2xij0zP63v5E3B5sN+iGX95z0Fxhk4R0C8REfBnpMwFm4F+DPwQv+nm\n5WBnbwt9X+r0v4DrzWw5/mybfynq9wCwxMxeds59pqj7U/jz4y/Gn9nzH5xz7wShIlJ2OkuqiIgU\naPORiIgUKBRERKRAoSAiIgUKBRERKVAoiIhIgUJBREQKFAoiIlLw/wMqOwFoFPiPMAAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8fd4cc3890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !python3\n",
    "# -*- coding:utf-8 -*-\n",
    "from numpy import *\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "LEARNING_RATE = 0.1\n",
    "NUM_ITERATIONS = 300\n",
    "\n",
    "\n",
    "def get_data(filename):\n",
    "    data = sklearn.datasets.load_svmlight_file(filename)\n",
    "    return data[0], data[1]\n",
    "\n",
    "\n",
    "def compute_loss(X, y, theta, b):\n",
    "    # hinge loss\n",
    "    loss = 0.0\n",
    "    for(dx, dy) in zip(X, y):\n",
    "        pred = dot(dx, theta) + b\n",
    "        loss += max(0, 1-dy*pred)\n",
    "    norm = linalg.norm(theta)**2\n",
    "    loss = mean(loss)+norm/2.0\n",
    "    return loss/shape(X)[0]\n",
    "\n",
    "\n",
    "def optimizer_GD(X_train, y_train, X_validation, y_validation, ini_theta, ini_b, learning_rate, num_iterations):\n",
    "    theta = ini_theta\n",
    "    b = ini_b\n",
    "    C = 1.1\n",
    "    Ltrain = []\n",
    "    Lvalidation = []\n",
    "    for i in xrange(num_iterations):\n",
    "        Ltrain.append(compute_loss(X_train, y_train, theta, b))\n",
    "        Lvalidation.append(compute_loss(X_validation, y_validation, theta, b))\n",
    "        print('Loss of the ', i, ' iteration for train:', Ltrain[i])\n",
    "        print('Loss of the ', i, ' iteration for validation:', Lvalidation[i])\n",
    "        G = zeros(shape=(len(theta), 1))\n",
    "        B = 0\n",
    "        for (dx,dy) in zip(X_train,y_train):\n",
    "            if 1-(dy*(dot(dx, theta)+b)) >= 0:\n",
    "                y = sum(dy)\n",
    "                G += -y*dx.T\n",
    "                B += -y\n",
    "        G = theta + C*G\n",
    "        B = C*B\n",
    "        theta = theta - learning_rate * G/shape(X_train)[0]\n",
    "        b = b - learning_rate * B/shape(X_train)[0]\n",
    "    return Ltrain, Lvalidation\n",
    "\n",
    "\n",
    "def main():\n",
    "    # load data\n",
    "    X, y = get_data('./data/australian_scale')\n",
    "    X = X.todense()\n",
    "    y = y.reshape(len(y), 1)\n",
    "\n",
    "    # devide dataset\n",
    "    X_train, X_validation, y_train, y_validation = sklearn.model_selection.train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    # initialize parameters\n",
    "    n = shape(X_train)[1]  # number of features\n",
    "    m_train = shape(X_train)[0]  # number of training examples\n",
    "    lr = LEARNING_RATE\n",
    "    num_iter = NUM_ITERATIONS\n",
    "    initial_theta = zeros(shape=(n, 1))\n",
    "    ini_b = 0\n",
    "\n",
    "    # Linear Classification and Gradient Descent\n",
    "    Ltrain, Lvalidation = optimizer_GD(X_train, y_train, X_validation, y_validation, initial_theta, ini_b, lr, num_iter)\n",
    "\n",
    "    # visualization\n",
    "    num_iter = xrange(num_iter)\n",
    "    plt.plot(num_iter, Ltrain, label='training_loss')\n",
    "    plt.plot(num_iter, Lvalidation, label='validation_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
